{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni4T_dwEHFVa"
   },
   "source": [
    "## CS 6120: Natural Language Processing - Prof. Ahmad Uzair\n",
    "\n",
    "### Assignment 2: Text Classification and Neural Network\n",
    "### Total Points: 100 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loQ22M-bCubq"
   },
   "source": [
    "In Assignment 2, you will be dealing with text classification using Multinomial Naive Bayes and Neural Networks. You will also be dealing with vector visualization. In the previous assingment you implemented Bag of Words as the feature selection method. However, in this assignment you will be using TF-IDF Vectorization instead of Bag of Words. We recommend starting with this assignment a little early as the datasets are quite large and several parts of the assignment might take long duration to execute. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3brglC1C0mZ"
   },
   "source": [
    "## Question 1 Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ1y75IoC3rE"
   },
   "source": [
    "In the first question you will be dealing with 20 News Group Dataset. You are required to implement TF-IDF vectorization from scratch and perform Multinomial Naive Bayes Classification on the News Group Dataset.\n",
    "You may use appropriate packages or modules for fitting the Multinomial Naive Bayes Model, however, the implementation of the TF-IDF Vectorization should be from the scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRjM45PyC8ML"
   },
   "source": [
    "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date.\n",
    "\n",
    "Link to the original dataset: http://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups\n",
    "\n",
    "You can also import the dataset from sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CmFf2INNDJRb"
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import  word_tokenize \n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AEp1SHe5DKCB"
   },
   "outputs": [],
   "source": [
    "# Import the 20 news group dataset utilizing sklearn library\n",
    "\n",
    "mydata_train = fetch_20newsgroups(subset = 'train')\n",
    "mydata_test = fetch_20newsgroups(subset = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OscOmcE0DMHa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# Print the news groups(target) in the dataset\n",
    "\n",
    "pprint(list(mydata_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JvQb2r0aDR_J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n",
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "# What is the type of 'mydata_train' and 'mydata_test'\n",
    "\n",
    "print(type(mydata_train))\n",
    "print(type(mydata_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ozzwyREhDaMK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "11314\n",
      "7532\n",
      "7532\n"
     ]
    }
   ],
   "source": [
    "# Check the length of the data\n",
    "\n",
    "print(len(mydata_train.data))\n",
    "print(len(mydata_train.filenames))\n",
    "print(len(mydata_test.data))\n",
    "print(len(mydata_test.filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlipMuEpDz-K"
   },
   "source": [
    "### Expected Output: \n",
    "11314\n",
    "\n",
    "11314\n",
    "\n",
    "7532\n",
    "\n",
    "7532"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55FKOBBuEDI2"
   },
   "source": [
    "## Extracting Features from the Dataset                        (20 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4GDENzmEEkG"
   },
   "source": [
    "In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgxfDXmxEHid"
   },
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8qNFFYyEKsa"
   },
   "source": [
    "Our model cannot simply read the text data so we convert it into numerical format. In order to convert the data into numerical format we create vectors from text.\n",
    "\n",
    "For this particular purpose we could either employ Bag of Words or TF-IDF Vectorization\n",
    "\n",
    "Bag of Words just creates a set of vectors containing the count of word occurrences in the document (reviews), while the TF-IDF model contains information on the more important words and the less important ones as well.\n",
    "\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency, which instead of giving more weight to words that occur more frequently, it gives a higher weight to words that occur less frequently.\n",
    "\n",
    "Ref:https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/#:~:text=Bag%20of%20Words%20just%20creates,less%20important%20ones%20as%20well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLzgRJRZEP3k"
   },
   "source": [
    "TF-IDF = Term Frequency (TF) * Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xe5lHi3NE1QJ"
   },
   "source": [
    "Term Frequency is the measure of the frequency of words in a document. It is the ratio of the number of times the word appears in a document compared to the total number of words in that document.\n",
    "\n",
    "The words that occur rarely in the corpus have a high IDF score. It is the log of the ratio of the number of documents to the number of documents containing the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXotAER_EQ8T"
   },
   "source": [
    "idf(t) = log(N/(df + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2vzVI8ylFAEl"
   },
   "outputs": [],
   "source": [
    "text = mydata_train.data\n",
    "test = mydata_test.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ2AatmvFtE-"
   },
   "source": [
    "## Preprocessing the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XyJbe42AFuHp"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "lines = [] \n",
    "word_list = [] \n",
    "\n",
    "for line in text:\n",
    "    #tokenize the text documents and update the lists word_list and lines\n",
    "\n",
    "    line = line.lower()\n",
    "    line = word_tokenize(line)\n",
    "    line = [word for word in line if word.isalpha()]\n",
    "    lines.append(line)\n",
    "    \n",
    "    additions = [word for word in line if word not in word_list] #new words, though there may be duplicates IN this list\n",
    "    for word in additions:\n",
    "        if word in word_list:\n",
    "            continue\n",
    "        else:\n",
    "            word_list.append(word)\n",
    "        \n",
    "# Make sure the word_list contains unique tokens || forced this in construction\n",
    "# word_list = \n",
    "\n",
    "# Calculate the total documents present in the corpus\n",
    "total_docs = len(text)\n",
    " \n",
    "#Create a dictionary to keep track of index of each word\n",
    "dict_idx = {}\n",
    "for i in range(len(word_list)):\n",
    "    dict_idx[word_list[i]] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "E6M_CoI9FxYb"
   },
   "outputs": [],
   "source": [
    "# Create a frequency dictionary\n",
    "\n",
    "def frequency_dict(lines):\n",
    "    '''\n",
    "    lines: list containing all the tokens\n",
    "    ---\n",
    "    freq_word: returns a dictionary which keeps the count of the number of documents containing the given word\n",
    "    '''\n",
    "\n",
    "    freq_word = {}\n",
    "\n",
    "    for line in lines:\n",
    "        words_seen = []\n",
    "        for word in line:\n",
    "            if word in freq_word.keys() and word not in words_seen:\n",
    "                freq_word[word] += 1\n",
    "                words_seen.append(word)\n",
    "                continue\n",
    "            if word not in words_seen:\n",
    "                freq_word[word] = 1\n",
    "                words_seen.append(word)\n",
    "                continue\n",
    "    \n",
    "    #for word in word_list: AHHH, the bad way\n",
    "    #    freq_word[word] = 0\n",
    "    #    for line in lines:\n",
    "    #        if word in line:\n",
    "    #            freq_word[word] += 1\n",
    "    return freq_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qFkt9KBgFz43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "73243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'from': 11314,\n",
       " 'lerxst': 2,\n",
       " 'where': 1824,\n",
       " 'my': 4456,\n",
       " 'thing': 1193,\n",
       " 'subject': 11314,\n",
       " 'what': 4473,\n",
       " 'car': 561,\n",
       " 'is': 8648,\n",
       " 'this': 6803,\n",
       " 'organization': 10867,\n",
       " 'university': 4427,\n",
       " 'of': 9885,\n",
       " 'maryland': 99,\n",
       " 'college': 517,\n",
       " 'park': 170,\n",
       " 'lines': 11277,\n",
       " 'i': 9379,\n",
       " 'was': 4665,\n",
       " 'wondering': 295,\n",
       " 'if': 5828,\n",
       " 'anyone': 2099,\n",
       " 'out': 3529,\n",
       " 'there': 4508,\n",
       " 'could': 2473,\n",
       " 'enlighten': 27,\n",
       " 'me': 3877,\n",
       " 'on': 6846,\n",
       " 'saw': 368,\n",
       " 'the': 10553,\n",
       " 'other': 2855,\n",
       " 'day': 908,\n",
       " 'it': 8083,\n",
       " 'a': 9862,\n",
       " 'sports': 103,\n",
       " 'looked': 273,\n",
       " 'to': 9869,\n",
       " 'be': 6434,\n",
       " 'late': 242,\n",
       " 'early': 361,\n",
       " 'called': 779,\n",
       " 'bricklin': 4,\n",
       " 'doors': 69,\n",
       " 'were': 2363,\n",
       " 'really': 1590,\n",
       " 'small': 590,\n",
       " 'in': 9456,\n",
       " 'addition': 210,\n",
       " 'front': 324,\n",
       " 'bumper': 28,\n",
       " 'separate': 176,\n",
       " 'rest': 428,\n",
       " 'body': 308,\n",
       " 'all': 4372,\n",
       " 'know': 3280,\n",
       " 'can': 4801,\n",
       " 'tellme': 2,\n",
       " 'model': 297,\n",
       " 'name': 741,\n",
       " 'engine': 187,\n",
       " 'specs': 106,\n",
       " 'years': 1294,\n",
       " 'production': 101,\n",
       " 'made': 1100,\n",
       " 'history': 393,\n",
       " 'or': 5746,\n",
       " 'whatever': 408,\n",
       " 'info': 632,\n",
       " 'you': 6548,\n",
       " 'have': 6766,\n",
       " 'funky': 7,\n",
       " 'looking': 821,\n",
       " 'please': 1694,\n",
       " 'thanks': 1728,\n",
       " 'il': 117,\n",
       " 'brought': 232,\n",
       " 'by': 4276,\n",
       " 'your': 3290,\n",
       " 'neighborhood': 30,\n",
       " 'guykuo': 9,\n",
       " 'guy': 375,\n",
       " 'kuo': 16,\n",
       " 'si': 59,\n",
       " 'clock': 168,\n",
       " 'poll': 31,\n",
       " 'final': 253,\n",
       " 'call': 795,\n",
       " 'summary': 535,\n",
       " 'for': 8267,\n",
       " 'reports': 219,\n",
       " 'keywords': 952,\n",
       " 'acceleration': 34,\n",
       " 'upgrade': 126,\n",
       " 'washington': 371,\n",
       " 'fair': 165,\n",
       " 'number': 919,\n",
       " 'brave': 36,\n",
       " 'souls': 34,\n",
       " 'who': 3149,\n",
       " 'upgraded': 40,\n",
       " 'their': 2469,\n",
       " 'oscillator': 18,\n",
       " 'shared': 87,\n",
       " 'experiences': 99,\n",
       " 'send': 646,\n",
       " 'brief': 67,\n",
       " 'message': 717,\n",
       " 'detailing': 18,\n",
       " 'with': 6360,\n",
       " 'procedure': 61,\n",
       " 'top': 421,\n",
       " 'speed': 397,\n",
       " 'attained': 7,\n",
       " 'cpu': 118,\n",
       " 'rated': 41,\n",
       " 'add': 355,\n",
       " 'cards': 242,\n",
       " 'and': 9386,\n",
       " 'adapters': 23,\n",
       " 'heat': 93,\n",
       " 'sinks': 10,\n",
       " 'hour': 95,\n",
       " 'usage': 61,\n",
       " 'per': 327,\n",
       " 'floppy': 143,\n",
       " 'disk': 354,\n",
       " 'functionality': 38,\n",
       " 'm': 290,\n",
       " 'floppies': 36,\n",
       " 'are': 6000,\n",
       " 'especially': 476,\n",
       " 'requested': 56,\n",
       " 'will': 3766,\n",
       " 'summarizing': 10,\n",
       " 'next': 812,\n",
       " 'two': 1748,\n",
       " 'days': 560,\n",
       " 'so': 4058,\n",
       " 'network': 394,\n",
       " 'knowledge': 297,\n",
       " 'base': 241,\n",
       " 'done': 789,\n",
       " 'answered': 91,\n",
       " 'twillis': 1,\n",
       " 'thomas': 275,\n",
       " 'e': 284,\n",
       " 'willis': 18,\n",
       " 'pb': 29,\n",
       " 'questions': 585,\n",
       " 'purdue': 106,\n",
       " 'engineering': 558,\n",
       " 'computer': 1507,\n",
       " 'distribution': 2631,\n",
       " 'usa': 1533,\n",
       " 'well': 2124,\n",
       " 'folks': 266,\n",
       " 'mac': 349,\n",
       " 'plus': 331,\n",
       " 'finally': 306,\n",
       " 'gave': 272,\n",
       " 'up': 2937,\n",
       " 'ghost': 21,\n",
       " 'weekend': 74,\n",
       " 'after': 1636,\n",
       " 'starting': 206,\n",
       " 'life': 692,\n",
       " 'as': 5131,\n",
       " 'way': 2009,\n",
       " 'back': 1362,\n",
       " 'sooo': 4,\n",
       " 'market': 227,\n",
       " 'new': 2188,\n",
       " 'machine': 439,\n",
       " 'bit': 793,\n",
       " 'sooner': 49,\n",
       " 'than': 2697,\n",
       " 'intended': 189,\n",
       " 'into': 1895,\n",
       " 'picking': 45,\n",
       " 'powerbook': 49,\n",
       " 'maybe': 807,\n",
       " 'bunch': 195,\n",
       " 'that': 8003,\n",
       " 'hopefully': 119,\n",
       " 'somebody': 272,\n",
       " 'answer': 534,\n",
       " 'does': 3339,\n",
       " 'anybody': 565,\n",
       " 'any': 4130,\n",
       " 'dirt': 36,\n",
       " 'when': 3076,\n",
       " 'round': 154,\n",
       " 'introductions': 1,\n",
       " 'expected': 198,\n",
       " 'heard': 724,\n",
       " 'supposed': 273,\n",
       " 'make': 1968,\n",
       " 'an': 4664,\n",
       " 'appearence': 2,\n",
       " 'summer': 135,\n",
       " 'but': 5818,\n",
       " 'anymore': 140,\n",
       " 'since': 1518,\n",
       " 'do': 5643,\n",
       " 'access': 685,\n",
       " 'macleak': 2,\n",
       " 'had': 2365,\n",
       " 'more': 3179,\n",
       " 'has': 3918,\n",
       " 'rumors': 42,\n",
       " 'about': 4220,\n",
       " 'price': 501,\n",
       " 'drops': 40,\n",
       " 'line': 685,\n",
       " 'like': 3567,\n",
       " 'ones': 386,\n",
       " 'duo': 43,\n",
       " 'just': 3486,\n",
       " 'went': 406,\n",
       " 'through': 1079,\n",
       " 'recently': 405,\n",
       " 'impression': 97,\n",
       " 'display': 284,\n",
       " 'probably': 1065,\n",
       " 'swing': 25,\n",
       " 'got': 1252,\n",
       " 'rather': 869,\n",
       " 'feel': 522,\n",
       " 'how': 3071,\n",
       " 'much': 1977,\n",
       " 'better': 1223,\n",
       " 'yea': 20,\n",
       " 'looks': 396,\n",
       " 'great': 958,\n",
       " 'store': 139,\n",
       " 'wow': 66,\n",
       " 'good': 2300,\n",
       " 'solicit': 6,\n",
       " 'some': 3519,\n",
       " 'opinions': 737,\n",
       " 'people': 2539,\n",
       " 'use': 2187,\n",
       " 'its': 1474,\n",
       " 'worth': 360,\n",
       " 'taking': 358,\n",
       " 'size': 334,\n",
       " 'money': 533,\n",
       " 'hit': 318,\n",
       " 'get': 3014,\n",
       " 'active': 117,\n",
       " 'realize': 232,\n",
       " 'real': 888,\n",
       " 'subjective': 49,\n",
       " 'question': 1312,\n",
       " 'only': 2996,\n",
       " 'played': 187,\n",
       " 'around': 1045,\n",
       " 'machines': 243,\n",
       " 'breifly': 3,\n",
       " 'figured': 64,\n",
       " 'actually': 951,\n",
       " 'uses': 400,\n",
       " 'daily': 123,\n",
       " 'might': 1329,\n",
       " 'prove': 223,\n",
       " 'helpful': 118,\n",
       " 'hellcats': 2,\n",
       " 'perform': 106,\n",
       " 'advance': 497,\n",
       " 'email': 760,\n",
       " 'post': 862,\n",
       " 'news': 634,\n",
       " 'reading': 426,\n",
       " 'time': 2338,\n",
       " 'at': 5028,\n",
       " 'premium': 23,\n",
       " 'finals': 52,\n",
       " 'corner': 81,\n",
       " 'tom': 249,\n",
       " 'electrical': 161,\n",
       " 'convictions': 30,\n",
       " 'dangerous': 177,\n",
       " 'enemies': 39,\n",
       " 'truth': 317,\n",
       " 'lies': 115,\n",
       " 'nietzsche': 12,\n",
       " 'jgreen': 19,\n",
       " 'amber': 7,\n",
       " 'joe': 207,\n",
       " 'green': 169,\n",
       " 're': 7485,\n",
       " 'weitek': 13,\n",
       " 'harris': 43,\n",
       " 'systems': 813,\n",
       " 'division': 381,\n",
       " 'world': 1861,\n",
       " 'tin': 518,\n",
       " 'version': 882,\n",
       " 'robert': 490,\n",
       " 'kyanko': 5,\n",
       " 'rob': 148,\n",
       " 'wrote': 810,\n",
       " 'abraxis': 2,\n",
       " 'writes': 5751,\n",
       " 'article': 4912,\n",
       " 'graphics': 382,\n",
       " 'chip': 487,\n",
       " 'far': 950,\n",
       " 'stuff': 567,\n",
       " 'goes': 457,\n",
       " 'pretty': 649,\n",
       " 'nice': 500,\n",
       " 'quadrilateral': 2,\n",
       " 'fill': 83,\n",
       " 'command': 187,\n",
       " 'requires': 191,\n",
       " 'four': 344,\n",
       " 'points': 302,\n",
       " 'information': 1020,\n",
       " 'corporation': 405,\n",
       " 'scares': 15,\n",
       " 'person': 676,\n",
       " 'no': 3724,\n",
       " 'sense': 429,\n",
       " 'humor': 52,\n",
       " 'jonathan': 95,\n",
       " 'winters': 8,\n",
       " 'jcm': 2,\n",
       " 'mcdowell': 16,\n",
       " 'shuttle': 95,\n",
       " 'launch': 125,\n",
       " 'smithsonian': 10,\n",
       " 'astrophysical': 9,\n",
       " 'observatory': 45,\n",
       " 'cambridge': 183,\n",
       " 'ma': 370,\n",
       " 'sci': 121,\n",
       " 'tombaker': 2,\n",
       " 'baker': 36,\n",
       " 'etrat': 4,\n",
       " 'pack': 76,\n",
       " 'rat': 33,\n",
       " 'clear': 397,\n",
       " 'caution': 23,\n",
       " 'warning': 162,\n",
       " 'memory': 429,\n",
       " 'verify': 45,\n",
       " 'unexpected': 17,\n",
       " 'errors': 163,\n",
       " 'am': 2232,\n",
       " 'error': 269,\n",
       " 'sorry': 503,\n",
       " 'dumb': 70,\n",
       " 'parity': 25,\n",
       " 'previously': 114,\n",
       " 'known': 453,\n",
       " 'conditions': 122,\n",
       " 'waivered': 2,\n",
       " 'yes': 764,\n",
       " 'we': 2936,\n",
       " 'already': 658,\n",
       " 'knew': 226,\n",
       " 'curious': 148,\n",
       " 'meaning': 209,\n",
       " 'quote': 196,\n",
       " 'understanding': 210,\n",
       " 'basically': 235,\n",
       " 'bugs': 71,\n",
       " 'system': 1313,\n",
       " 'software': 756,\n",
       " 'things': 1206,\n",
       " 'checked': 117,\n",
       " 'right': 1625,\n",
       " 'values': 162,\n",
       " 'yet': 779,\n",
       " 'because': 1943,\n",
       " 'they': 4473,\n",
       " 'set': 786,\n",
       " 'till': 65,\n",
       " 'suchlike': 4,\n",
       " 'fix': 149,\n",
       " 'code': 487,\n",
       " 'possibly': 250,\n",
       " 'introduce': 37,\n",
       " 'tell': 999,\n",
       " 'crew': 50,\n",
       " 'see': 1927,\n",
       " 'before': 1354,\n",
       " 'liftoff': 10,\n",
       " 'ignore': 116,\n",
       " 'dfo': 5,\n",
       " 'foxvog': 5,\n",
       " 'douglas': 145,\n",
       " 'rewording': 7,\n",
       " 'second': 764,\n",
       " 'amendment': 142,\n",
       " 'ideas': 299,\n",
       " 'vtt': 2,\n",
       " 'cdt': 67,\n",
       " 'tavares': 56,\n",
       " 'jrutledg': 12,\n",
       " 'john': 797,\n",
       " 'lawrence': 129,\n",
       " 'rutledge': 13,\n",
       " 'massive': 74,\n",
       " 'destructive': 23,\n",
       " 'power': 794,\n",
       " 'many': 1763,\n",
       " 'modern': 208,\n",
       " 'weapons': 215,\n",
       " 'makes': 689,\n",
       " 'cost': 445,\n",
       " 'accidental': 30,\n",
       " 'crimial': 2,\n",
       " 'these': 2164,\n",
       " 'mass': 171,\n",
       " 'destruction': 50,\n",
       " 'need': 1693,\n",
       " 'control': 592,\n",
       " 'government': 774,\n",
       " 'individual': 253,\n",
       " 'would': 4477,\n",
       " 'result': 340,\n",
       " 'needless': 37,\n",
       " 'deaths': 82,\n",
       " 'millions': 115,\n",
       " 'keep': 801,\n",
       " 'bear': 141,\n",
       " 'stating': 54,\n",
       " 'coming': 348,\n",
       " 'say': 1708,\n",
       " 'disagree': 152,\n",
       " 'every': 1007,\n",
       " 'count': 174,\n",
       " 'believe': 1258,\n",
       " 'individuals': 181,\n",
       " 'should': 2229,\n",
       " 'own': 1199,\n",
       " 'find': 1355,\n",
       " 'hard': 772,\n",
       " 'support': 738,\n",
       " 'neighbor': 79,\n",
       " 'nuclear': 111,\n",
       " 'biological': 30,\n",
       " 'nerve': 33,\n",
       " 'gas': 206,\n",
       " 'property': 129,\n",
       " 'not': 6236,\n",
       " 'even': 2146,\n",
       " 'agree': 559,\n",
       " 'keeping': 179,\n",
       " 'hands': 203,\n",
       " 'hope': 640,\n",
       " 'us': 1487,\n",
       " 'sign': 153,\n",
       " 'blank': 50,\n",
       " 'checks': 41,\n",
       " 'course': 1004,\n",
       " 'term': 211,\n",
       " 'must': 1170,\n",
       " 'rigidly': 2,\n",
       " 'defined': 144,\n",
       " 'bill': 498,\n",
       " 'doug': 180,\n",
       " 'says': 864,\n",
       " 'he': 2285,\n",
       " 'means': 683,\n",
       " 'cbw': 3,\n",
       " 'nukes': 9,\n",
       " 'sarah': 16,\n",
       " 'brady': 26,\n",
       " 'she': 390,\n",
       " 'street': 213,\n",
       " 'sweeper': 7,\n",
       " 'shotguns': 20,\n",
       " 'sks': 6,\n",
       " 'rifles': 38,\n",
       " 'doubt': 325,\n",
       " 'using': 1269,\n",
       " 'allegedly': 22,\n",
       " 'her': 376,\n",
       " 'then': 2305,\n",
       " 'immediately': 157,\n",
       " 'follows': 172,\n",
       " 'thousands': 155,\n",
       " 'killed': 295,\n",
       " 'each': 869,\n",
       " 'year': 1006,\n",
       " 'handguns': 65,\n",
       " 'easily': 301,\n",
       " 'reduced': 81,\n",
       " 'putting': 211,\n",
       " 'reasonable': 274,\n",
       " 'restrictions': 79,\n",
       " 'them': 2563,\n",
       " 'mean': 827,\n",
       " 'read': 1140,\n",
       " 'presenting': 30,\n",
       " 'first': 1774,\n",
       " 'argument': 334,\n",
       " 'commonly': 61,\n",
       " 'understood': 93,\n",
       " 'switching': 53,\n",
       " 'topics': 58,\n",
       " 'point': 1239,\n",
       " 'evidently': 23,\n",
       " 'show': 543,\n",
       " 'allowed': 246,\n",
       " 'later': 480,\n",
       " 'analysis': 150,\n",
       " 'given': 674,\n",
       " 'consider': 486,\n",
       " 'another': 1269,\n",
       " 'class': 239,\n",
       " 'speak': 297,\n",
       " 'company': 438,\n",
       " 'write': 440,\n",
       " 'today': 696,\n",
       " 'special': 329,\n",
       " 'investors': 40,\n",
       " 'packet': 74,\n",
       " 'bmdelane': 5,\n",
       " 'brian': 276,\n",
       " 'manning': 14,\n",
       " 'delaney': 5,\n",
       " 'brain': 153,\n",
       " 'tumor': 7,\n",
       " 'treatment': 143,\n",
       " 'chicago': 282,\n",
       " 'few': 1163,\n",
       " 'responded': 67,\n",
       " 'request': 246,\n",
       " 'astrocytomas': 1,\n",
       " 'whom': 182,\n",
       " 'thank': 318,\n",
       " 'directly': 282,\n",
       " 'probs': 6,\n",
       " 'sean': 65,\n",
       " 'debra': 3,\n",
       " 'sharon': 21,\n",
       " 'thought': 811,\n",
       " 'publicly': 76,\n",
       " 'everyone': 548,\n",
       " 'sure': 1294,\n",
       " 'glad': 117,\n",
       " 'accidentally': 24,\n",
       " 'rn': 16,\n",
       " 'instead': 531,\n",
       " 'rm': 74,\n",
       " 'trying': 781,\n",
       " 'delete': 52,\n",
       " 'file': 542,\n",
       " 'last': 1286,\n",
       " 'september': 45,\n",
       " 'hmmm': 99,\n",
       " 'bgrubb': 21,\n",
       " 'grubb': 22,\n",
       " 'ide': 120,\n",
       " 'vs': 182,\n",
       " 'scsi': 177,\n",
       " 'mexico': 67,\n",
       " 'state': 1218,\n",
       " 'las': 26,\n",
       " 'cruces': 11,\n",
       " 'nm': 31,\n",
       " 'pc': 372,\n",
       " 'magazine': 176,\n",
       " 'april': 414,\n",
       " 'although': 497,\n",
       " 'twice': 133,\n",
       " 'fasst': 6,\n",
       " 'esdi': 23,\n",
       " 'faster': 225,\n",
       " 'devices': 177,\n",
       " 'acceptance': 65,\n",
       " 'long': 1051,\n",
       " 'been': 2551,\n",
       " 'stalled': 9,\n",
       " 'incompatability': 6,\n",
       " 'problems': 754,\n",
       " 'installation': 82,\n",
       " 'headaches': 27,\n",
       " 'love': 455,\n",
       " 'writers': 43,\n",
       " 'stupid': 264,\n",
       " 'statements': 149,\n",
       " 'performance': 274,\n",
       " 'those': 1846,\n",
       " 'numbers': 379,\n",
       " 'list': 620,\n",
       " 'actual': 193,\n",
       " 'ranges': 24,\n",
       " 'which': 3025,\n",
       " 'convince': 110,\n",
       " 'such': 1704,\n",
       " 'statement': 341,\n",
       " 'absurd': 54,\n",
       " 'always': 778,\n",
       " 'versions': 138,\n",
       " 'shows': 231,\n",
       " 'controler': 14,\n",
       " 'range': 208,\n",
       " 'indeed': 274,\n",
       " 'controller': 179,\n",
       " 'burst': 31,\n",
       " 'note': 594,\n",
       " 'increase': 170,\n",
       " 'quadra': 93,\n",
       " 'exist': 303,\n",
       " 'too': 1641,\n",
       " 'mode': 270,\n",
       " 'fast': 375,\n",
       " 'data': 647,\n",
       " 'correct': 451,\n",
       " 'reach': 131,\n",
       " 'facts': 190,\n",
       " 'posted': 398,\n",
       " 'newsgroup': 267,\n",
       " 'ibm': 257,\n",
       " 'sheet': 79,\n",
       " 'available': 788,\n",
       " 'ftp': 270,\n",
       " 'may': 1788,\n",
       " 'still': 1480,\n",
       " 'part': 967,\n",
       " 'problem': 1373,\n",
       " 'both': 1178,\n",
       " 'inconsiant': 2,\n",
       " 'though': 956,\n",
       " 'documented': 41,\n",
       " 'apple': 259,\n",
       " 'salesperson': 7,\n",
       " 'said': 1307,\n",
       " 'maximum': 94,\n",
       " 'synchronous': 16,\n",
       " 'ansynchronous': 2,\n",
       " 'slower': 87,\n",
       " 'seems': 1038,\n",
       " 'interface': 181,\n",
       " 'think': 2681,\n",
       " 'driven': 104,\n",
       " 'true': 873,\n",
       " 'go': 1631,\n",
       " 'slam': 12,\n",
       " 'understand': 536,\n",
       " 'going': 1309,\n",
       " 'one': 4289,\n",
       " 'reference': 280,\n",
       " 'digital': 213,\n",
       " 'review': 152,\n",
       " 'oct': 22,\n",
       " 'win': 417,\n",
       " 'icon': 44,\n",
       " 'help': 1337,\n",
       " 'northern': 85,\n",
       " 'iowa': 81,\n",
       " 'downloaded': 29,\n",
       " 'several': 685,\n",
       " 'icons': 36,\n",
       " 'bmp': 26,\n",
       " 'ca': 1814,\n",
       " 'figure': 306,\n",
       " 'change': 545,\n",
       " 'wallpaper': 14,\n",
       " 'appreciated': 394,\n",
       " 'thanx': 99,\n",
       " 'ps': 126,\n",
       " 'kerr': 15,\n",
       " 'stan': 48,\n",
       " 'sigma': 13,\n",
       " 'designs': 51,\n",
       " 'double': 129,\n",
       " 'illinois': 268,\n",
       " 'urbana': 154,\n",
       " 'joseph': 174,\n",
       " 'pellettiere': 2,\n",
       " 'board': 325,\n",
       " 'hardware': 346,\n",
       " 'compression': 80,\n",
       " 'works': 595,\n",
       " 'autodoubler': 2,\n",
       " 'also': 2569,\n",
       " 'over': 1513,\n",
       " 'work': 1529,\n",
       " 'diskdoubler': 1,\n",
       " 'due': 394,\n",
       " 'licensing': 40,\n",
       " 'stac': 2,\n",
       " 'technologies': 107,\n",
       " 'owners': 151,\n",
       " 'technology': 748,\n",
       " 'writing': 208,\n",
       " 'lost': 343,\n",
       " 'wrong': 802,\n",
       " 'being': 1610,\n",
       " 'whether': 648,\n",
       " 'fault': 154,\n",
       " 'something': 1551,\n",
       " 'else': 904,\n",
       " 'however': 1056,\n",
       " 'decompress': 3,\n",
       " 'troubled': 7,\n",
       " 'recompress': 2,\n",
       " 'without': 1201,\n",
       " 'usually': 442,\n",
       " 'reappears': 4,\n",
       " 'above': 732,\n",
       " 'mentioned': 358,\n",
       " 'freeware': 17,\n",
       " 'expansion': 134,\n",
       " 'utility': 94,\n",
       " 'dd': 21,\n",
       " 'expand': 59,\n",
       " 'unless': 529,\n",
       " 'installed': 213,\n",
       " 'product': 241,\n",
       " 'now': 2150,\n",
       " 'unlikely': 111,\n",
       " 'holes': 88,\n",
       " 'related': 247,\n",
       " 'fixed': 135,\n",
       " 'sad': 99,\n",
       " 'very': 2023,\n",
       " 'reluctant': 16,\n",
       " 'buy': 563,\n",
       " 'stinky': 1,\n",
       " 'hey': 235,\n",
       " 'competition': 54,\n",
       " 'computing': 343,\n",
       " 'communications': 387,\n",
       " 'services': 469,\n",
       " 'office': 370,\n",
       " 'u': 292,\n",
       " 'phone': 654,\n",
       " 'stankerr': 2,\n",
       " 'irwin': 6,\n",
       " 'arnstein': 5,\n",
       " 'recommendation': 22,\n",
       " 'duc': 12,\n",
       " 'expires': 121,\n",
       " 'sat': 83,\n",
       " 'gmt': 491,\n",
       " 'computrac': 6,\n",
       " 'richardson': 50,\n",
       " 'tx': 175,\n",
       " 'ducati': 22,\n",
       " 'gts': 4,\n",
       " 'runs': 290,\n",
       " 'paint': 78,\n",
       " 'faded': 5,\n",
       " 'leaks': 17,\n",
       " 'oil': 115,\n",
       " 'pops': 26,\n",
       " 'accel': 6,\n",
       " 'shop': 84,\n",
       " 'trans': 13,\n",
       " 'leak': 22,\n",
       " 'sold': 185,\n",
       " 'bike': 272,\n",
       " 'owner': 137,\n",
       " 'want': 1736,\n",
       " 'thinking': 364,\n",
       " 'stable': 64,\n",
       " 'mate': 7,\n",
       " 'beemer': 10,\n",
       " 'jap': 8,\n",
       " 'myself': 417,\n",
       " 'axis': 27,\n",
       " 'motors': 27,\n",
       " 'tuba': 4,\n",
       " 'honk': 7,\n",
       " 'therefore': 367,\n",
       " 'dod': 380,\n",
       " 'david': 923,\n",
       " 'bold': 24,\n",
       " 'popular': 178,\n",
       " 'morality': 140,\n",
       " 'camtec': 4,\n",
       " 'electronics': 137,\n",
       " 'ericsson': 25,\n",
       " 'leicester': 6,\n",
       " 'england': 111,\n",
       " 'bangkok': 4,\n",
       " 'james': 375,\n",
       " 'owens': 9,\n",
       " 'previous': 359,\n",
       " 'rude': 23,\n",
       " 'hold': 358,\n",
       " 'end': 791,\n",
       " 'different': 886,\n",
       " 'stick': 149,\n",
       " 'look': 1109,\n",
       " 'posting': 503,\n",
       " 'again': 996,\n",
       " 'intent': 87,\n",
       " 'explaining': 43,\n",
       " 'jung': 9,\n",
       " 'moral': 205,\n",
       " 'god': 807,\n",
       " 'overlooked': 12,\n",
       " 'main': 290,\n",
       " 'seem': 713,\n",
       " 'saying': 525,\n",
       " 'unknowable': 6,\n",
       " 'his': 1781,\n",
       " 'yep': 40,\n",
       " 'jew': 69,\n",
       " 'jewish': 259,\n",
       " 'jews': 277,\n",
       " 'covenant': 19,\n",
       " 'between': 1082,\n",
       " 'yhwh': 2,\n",
       " 'patriarchs': 2,\n",
       " 'abraham': 28,\n",
       " 'moses': 23,\n",
       " 'case': 1168,\n",
       " 'establishes': 13,\n",
       " 'follow': 273,\n",
       " 'mankind': 49,\n",
       " 'decide': 180,\n",
       " 'boundaries': 27,\n",
       " 'fall': 222,\n",
       " 'sadducees': 2,\n",
       " 'believed': 134,\n",
       " 'torah': 16,\n",
       " 'required': 281,\n",
       " 'whereas': 71,\n",
       " 'pharisees': 13,\n",
       " 'ancestors': 18,\n",
       " 'judaism': 37,\n",
       " 'interpretation': 113,\n",
       " 'lead': 210,\n",
       " 'nuances': 6,\n",
       " 'talmud': 3,\n",
       " 'essence': 40,\n",
       " 'biblical': 125,\n",
       " 'man': 646,\n",
       " 'christian': 460,\n",
       " 'necessarily': 296,\n",
       " 'indicate': 89,\n",
       " 'anything': 1101,\n",
       " 'outside': 297,\n",
       " 'relationship': 110,\n",
       " 'speculate': 31,\n",
       " 'comes': 562,\n",
       " 'mind': 525,\n",
       " 'created': 261,\n",
       " 'image': 266,\n",
       " 'committed': 139,\n",
       " 'live': 546,\n",
       " 'christ': 282,\n",
       " 'example': 690,\n",
       " 'pressed': 36,\n",
       " 'argue': 172,\n",
       " 'kind': 704,\n",
       " 'trouble': 247,\n",
       " 'come': 1037,\n",
       " 'conclusion': 146,\n",
       " 'upsets': 3,\n",
       " 'cart': 10,\n",
       " 'wants': 314,\n",
       " 'script': 34,\n",
       " 'shaky': 12,\n",
       " 'foundation': 119,\n",
       " 'mix': 73,\n",
       " 'metaphors': 3,\n",
       " 'unashamedly': 1,\n",
       " 'living': 300,\n",
       " 'little': 1110,\n",
       " 'jesus': 362,\n",
       " 'recorded': 45,\n",
       " 'utterances': 2,\n",
       " 'narratives': 5,\n",
       " 'followers': 70,\n",
       " 'references': 172,\n",
       " 'comtemporary': 1,\n",
       " 'historians': 19,\n",
       " 'revelation': 58,\n",
       " 'aside': 123,\n",
       " 'worse': 249,\n",
       " 'attempt': 215,\n",
       " 'debunk': 5,\n",
       " 'christianity': 204,\n",
       " 'initially': 43,\n",
       " 'bible': 321,\n",
       " 'interpret': 63,\n",
       " 'humanity': 67,\n",
       " 'guess': 546,\n",
       " 'faith': 263,\n",
       " 'relevation': 2,\n",
       " 'inherent': 46,\n",
       " 'subjectiveness': 2,\n",
       " 'metaphysically': 2,\n",
       " 'multiple': 157,\n",
       " 'codes': 51,\n",
       " 'absolute': 114,\n",
       " 'theologically': 7,\n",
       " 'questionable': 29,\n",
       " 'undoubtably': 5,\n",
       " 'founded': 50,\n",
       " 'parent': 56,\n",
       " 'child': 186,\n",
       " 'never': 1262,\n",
       " 'swear': 29,\n",
       " 'assume': 365,\n",
       " 'swears': 7,\n",
       " 'simply': 514,\n",
       " 'told': 507,\n",
       " 'trooper': 6,\n",
       " 'pub': 16,\n",
       " 'bar': 85,\n",
       " 'children': 366,\n",
       " 'wrongness': 4,\n",
       " 'here': 1876,\n",
       " 'disobeys': 2,\n",
       " 'inappropriate': 24,\n",
       " 'quite': 762,\n",
       " 'happy': 265,\n",
       " 'animals': 97,\n",
       " 'analogy': 67,\n",
       " 'water': 175,\n",
       " 'knows': 347,\n",
       " 'same': 1651,\n",
       " 'type': 404,\n",
       " 'gist': 8,\n",
       " 'incidentally': 28,\n",
       " 'young': 303,\n",
       " 'considers': 31,\n",
       " 'directive': 16,\n",
       " 'until': 665,\n",
       " 'gets': 408,\n",
       " 'older': 136,\n",
       " 'piaget': 2,\n",
       " 'learns': 10,\n",
       " 'religion': 297,\n",
       " 'oh': 592,\n",
       " 'sea': 101,\n",
       " 'fishes': 6,\n",
       " 'cried': 20,\n",
       " 'swam': 6,\n",
       " 'clearness': 4,\n",
       " 'rodc': 1,\n",
       " 'rod': 41,\n",
       " 'cerkoney': 1,\n",
       " 'hewlett': 30,\n",
       " 'packard': 37,\n",
       " 'fort': 46,\n",
       " 'collins': 56,\n",
       " 'co': 105,\n",
       " 'regards': 193,\n",
       " 'ms': 153,\n",
       " 'east': 225,\n",
       " 'harmony': 20,\n",
       " 'rd': 61,\n",
       " 'hpdesk': 2,\n",
       " 'mckissock': 8,\n",
       " 'space': 588,\n",
       " 'station': 209,\n",
       " 'redesign': 22,\n",
       " 'jsc': 15,\n",
       " 'alternative': 141,\n",
       " 'nasa': 226,\n",
       " 'lewis': 107,\n",
       " 'research': 755,\n",
       " 'center': 707,\n",
       " 'cleveland': 208,\n",
       " 'ohio': 231,\n",
       " 'vnews': 147,\n",
       " 'kjenks': 13,\n",
       " 'description': 144,\n",
       " 'external': 155,\n",
       " 'tank': 92,\n",
       " 'option': 180,\n",
       " 'ssf': 14,\n",
       " 'deleted': 321,\n",
       " 'mark': 554,\n",
       " 'proposed': 148,\n",
       " 'design': 293,\n",
       " 'shea': 17,\n",
       " 'committee': 109,\n",
       " 'crystal': 43,\n",
       " 'city': 364,\n",
       " 'warmly': 6,\n",
       " 'received': 250,\n",
       " 'hear': 401,\n",
       " 'based': 552,\n",
       " 'wingless': 5,\n",
       " 'orbiter': 21,\n",
       " 'likely': 431,\n",
       " 'yo': 27,\n",
       " 'ken': 192,\n",
       " 'let': 1180,\n",
       " 'options': 150,\n",
       " 'edition': 88,\n",
       " 'york': 361,\n",
       " 'times': 713,\n",
       " 'panel': 98,\n",
       " 'proposals': 35,\n",
       " 'dropped': 89,\n",
       " 'giant': 35,\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary containing the frequency of words utilizing the 'frequency_dict' function\n",
    "# Expect this chunk to take a comparatively longer time to execute since our dataset is large\n",
    "print(len(lines))\n",
    "print(len(word_list))\n",
    "freq_word = frequency_dict(lines)\n",
    "\n",
    "freq_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vLvPijR_GKHn"
   },
   "outputs": [],
   "source": [
    "# Create a function to calculate the Term Frequency\n",
    "\n",
    "def term_frequency(document, word):\n",
    "    '''\n",
    "    document: list containing the entire corpus\n",
    "    word: word whose term frequency is to be calculated\n",
    "    ---\n",
    "    tf: returns term frequency value\n",
    "    '''\n",
    "    tf = 0\n",
    "    for ele in document:\n",
    "        if ele == word:\n",
    "            tf += 1\n",
    "    \n",
    "    return tf/len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HA99G_yAGLCC"
   },
   "outputs": [],
   "source": [
    "# Create a function to calculate the Inverse Document Frequency\n",
    " \n",
    "def inverse_df(word):\n",
    "    '''\n",
    "    word: word whose inverse document frequency is to be calculated\n",
    "    ---\n",
    "    idf: return inverse document frequency value\n",
    "    '''\n",
    "    df = freq_word[word]\n",
    "    idf = math.log(len(lines)/df+1)\n",
    "    \n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "F0irgwv2GRfE"
   },
   "outputs": [],
   "source": [
    "#Create a function to combine the term frequencies (TF) and inverse document (IDF) frequencies calculated above to get TF-IDF\n",
    "\n",
    "def tfidf(sentence,dict_idx):\n",
    "    '''\n",
    "    sentence: list containing the entire corpus WHY CALL THIS SENTENCE AND NOT CORPUS? a sentence very obviously implies a small string of words...\n",
    "    dict: dictionary keeping track of index of each word\n",
    "    ---\n",
    "    tf_idf_vec: returns computed tf-idf\n",
    "    '''\n",
    "    num_words = len(dict_idx)\n",
    "    num_docs = len(sentence)\n",
    "    tf_idf_vec = np.zeros((num_words,num_docs)) #zeros array, to copy structure from linked site, 1 row per word, 1 column per mail\n",
    "    \n",
    "    for i in range(num_docs):\n",
    "        words_seen = []\n",
    "        for word in sentence[i]:\n",
    "            if word not in words_seen:\n",
    "                tf = term_frequency(sentence[i], word)\n",
    "                idf = inverse_df(word)\n",
    "                tf_idf_vec[dict_idx[word],i] = tf*idf\n",
    "                words_seen.append(word)\n",
    "        \n",
    "    return tf_idf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_VKJhqatGWpV"
   },
   "outputs": [],
   "source": [
    "#Compute the vectors utilizing the 'tfidf' function created above to obtain a TF-IDF Encoded text corpus\n",
    "\n",
    "vec = tfidf(lines, dict_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE0UGUaSGb8I"
   },
   "source": [
    "## Multinomial Naive Bayes (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yWYcxrdJGfDC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit a Multinomial Naive Bayes Model on our dataset\n",
    "model = MultinomialNB()\n",
    "model.fit(vec.T, list(mydata_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISCLAIMER: This cell was written before I realized that the cell below asks us to predict based on the TRAINING data,\n",
    "#not the test data.\n",
    "\n",
    "\n",
    "# Preprocessing the data for TEST\n",
    "\n",
    "\n",
    "#lines_test = [] \n",
    "#word_list_test = [] \n",
    "\n",
    "#for line in test:\n",
    "    #tokenize the text documents and update the lists word_list and lines\n",
    "\n",
    "#    line = line.lower()\n",
    "#    line = word_tokenize(line)\n",
    "#    line = [word for word in line if word.isalpha()]\n",
    "#    lines_test.append(line)\n",
    "    \n",
    "#    additions = [word for word in line if word not in word_list_test] #new words, though there may be duplicates IN this list\n",
    "#    for word in additions:\n",
    "#        if word in word_list_test:\n",
    "#            continue\n",
    "#        else:\n",
    "#            word_list_test.append(word)\n",
    "        \n",
    "# Make sure the word_list contains unique tokens || forced this in construction\n",
    "# word_list = \n",
    "\n",
    "# Calculate the total documents present in the corpus\n",
    "#total_docs = len(test)\n",
    " \n",
    "#Create a dictionary to keep track of index of each word\n",
    "#dict_idx_test = {}\n",
    "#for i in range(len(word_list_test)):\n",
    "#    dict_idx_test[word_list_test[i]] = i\n",
    "    \n",
    "def frequency_dict(lines):\n",
    "    '''\n",
    "    lines: list containing all the tokens\n",
    "    ---\n",
    "    freq_word: returns a dictionary which keeps the count of the number of documents containing the given word\n",
    "    '''\n",
    "\n",
    "    freq_word = {}\n",
    "\n",
    "    for line in lines:\n",
    "        words_seen = []\n",
    "        for word in line:\n",
    "            if word in freq_word.keys() and word not in words_seen:\n",
    "                freq_word[word] += 1\n",
    "                words_seen.append(word)\n",
    "                continue\n",
    "            if word not in words_seen:\n",
    "                freq_word[word] = 1\n",
    "                words_seen.append(word)\n",
    "                continue\n",
    "    \n",
    "    #for word in word_list: AHHH, the bad way\n",
    "    #    freq_word[word] = 0\n",
    "    #    for line in lines:\n",
    "    #        if word in line:\n",
    "    #            freq_word[word] += 1\n",
    "    return freq_word\n",
    "\n",
    "#freq_word_test = frequency_dict(lines_test)\n",
    "\n",
    "def inverse_df_test(word):\n",
    "    '''\n",
    "    word: word whose inverse document frequency is to be calculated\n",
    "    ---\n",
    "    idf: return inverse document frequency value\n",
    "    '''\n",
    "    df = freq_word_test[word]\n",
    "    idf = math.log(len(lines_test)/df+1)\n",
    "    \n",
    "    return idf\n",
    "\n",
    "def tfidf_test(sentence,dict_idx):\n",
    "    '''\n",
    "    sentence: list containing the entire corpus WHY CALL THIS SENTENCE AND NOT CORPUS? a sentence very obviously implies a small string of words...\n",
    "    dict: dictionary keeping track of index of each word\n",
    "    ---\n",
    "    tf_idf_vec: returns computed tf-idf\n",
    "    '''\n",
    "    num_words = len(dict_idx)\n",
    "    num_docs = len(sentence)\n",
    "    tf_idf_vec = np.zeros((num_words,num_docs)) #zeros array, to copy structure from linked site, 1 row per word, 1 column per mail\n",
    "    \n",
    "    for i in range(num_docs):\n",
    "        words_seen = []\n",
    "        for word in sentence[i]:\n",
    "            if word not in words_seen:\n",
    "                tf = term_frequency(sentence[i], word)\n",
    "                idf = inverse_df_test(word)\n",
    "                tf_idf_vec[dict_idx[word],i] = tf*idf\n",
    "                words_seen.append(word)\n",
    "        \n",
    "    return tf_idf_vec\n",
    "\n",
    "#vec_test = tfidf_test(lines_test, dict_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "G6CiQB4qGfqH"
   },
   "outputs": [],
   "source": [
    "#Perform testing on the train dataset\n",
    "\n",
    "pred = model.predict(vec.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yCLagGu6Gh6T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.8578538135255973\n",
      "Accuracy:  0.890931589181545\n"
     ]
    }
   ],
   "source": [
    "#Calculate the F1 Score and the Accuracy\n",
    "\n",
    "F1_score = metrics.f1_score(list(mydata_train.target), pred, average = 'macro')\n",
    "Accuracy = metrics.accuracy_score(list(mydata_train.target), pred)\n",
    "print(\"F1 Score: \", F1_score)\n",
    "print(\"Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbMRqJv5Gl2F"
   },
   "source": [
    "### Expected Output:\n",
    "F1 Score: 0.9533633964397735\n",
    "\n",
    "Accuracy: 0.9524482941488421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWRDuUqU-taV"
   },
   "source": [
    "Your accuracy does not have to be exactly the same. This is just to give you an estimate of what could you expect your accuracy to be around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfMc8cz93Cc0"
   },
   "source": [
    "## Question 2 Vector Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70iwEeL23F7K"
   },
   "source": [
    "In this unsupervised learning task we are going to cluster wikipedia articles into groups using T-SNE visualization after vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHx4YuxW36oM"
   },
   "source": [
    "### Collect articles from Wikipedia (10 points)\n",
    "\n",
    "In this section we will download articles from wikipedia and then vectorize them in the next step. You can select somewhat related topics or fetch the articles randomly. \n",
    "(Use dir() and help() functions or refer wikipedia documentation)\n",
    "You may also pick any other data source of your choice instead of wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jA419x6__mjg"
   },
   "outputs": [],
   "source": [
    "# install libraries\n",
    "#pip install wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vLMLk4K84Zbn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Roger Federer (German: [ˈrɔdʒər ˈfeːdərər]; born 8 August 1981) is a Swiss professional tennis player. He was ranked world No. 1 by the Association of Tennis Professionals (ATP) for 310 weeks, including a record 237 consecutive weeks, and has finished as the year-end No. 1 five times. He has won 103 ATP singles titles, the second most of all time after Jimmy Connors, including 20 Grand Slam titles, a record eight men's singles Wimbledon titles, and a record six year-end championships.\\nFederer has played in an era where he dominated men's tennis along with Rafael Nadal and Novak Djokovic. Referred to as the Big Three, they are considered by some to be the three greatest tennis players of all time. A Wimbledon junior champion in 1998, Federer won his first major singles title at Wimbledon in 2003 at age 21. In 2004, he won three of the four major singles titles and the ATP Finals, a feat he repeated in 2006 and 2007. From 2005 to 2010, he made 18 out of 19 major singles finals. During this span, he won five consecutive titles at both Wimbledon and the US Open. He completed the career Grand Slam at the 2009 French Open after three previous runner-up finishes to Nadal, his main rival until 2010. At age 27, he surpassed Pete Sampras' record of 14 major men's singles titles at Wimbledon in 2009.\\nAlthough Federer remained in the top 3 during most of the early 2010s, the success of Djokovic and Nadal ended his dominance over grass and hard courts. From mid-2010 through the end of 2016, he only won one major title. During this period, he and Stan Wawrinka led the Switzerland Davis Cup team to their first title in 2014, adding to the gold medal the pair won together in doubles at the 2008 Beijing Olympics. Federer also won a silver medal in singles from the 2012 London Olympics, where he finished runner-up to Andy Murray. After taking half a year off in late 2016 to recover from knee surgery, he had a renaissance at the majors, winning three more major titles over the next two years, including the 2017 Australian Open over Nadal and a record eighth men's singles Wimbledon title later in 2017. In 2018, he became the oldest ATP world No. 1 at age 36.\\nA versatile all-court player, Federer's perceived effortlessness has made him highly popular among tennis fans. Originally lacking self-control as a junior, he transformed his on-court demeanor to become well-liked for his general graciousness, winning the Stefan Edberg Sportsmanship Award 13 times. He has also won the Laureus World Sportsman of the Year award a record five times. Outside of competing, he played an instrumental role in the creation of the Laver Cup team competition. He is also an active philanthropist. He established the Roger Federer Foundation, which targets impoverished children in southern Africa, and has raised funds in part through the Match for Africa exhibition series. He is routinely one of the top ten highest-paid athletes in any sport and ranked first among all athletes with $100 million in endorsement income in 2020.\\n\\n\", \"Rafael Nadal Parera (Catalan: [rəf(ə)ˈɛl nəˈðal pəˈɾeɾə], Spanish: [rafaˈel naˈðal paˈɾeɾa]; born 3 June 1986) is a Spanish professional tennis player, currently ranked world No. 4 in singles by the Association of Tennis Professionals (ATP). He has been ranked world No. 1 for 209 weeks, and has finished as the year-end No. 1 five times. Nadal has won 22 Grand Slam men's singles titles, the most in history, including a record 14 French Open titles. He has won 92 ATP singles titles (including 36 Masters titles), with 63 of these on clay. Nadal's 81 consecutive wins on clay is the longest single-surface win streak in the Open Era.\\nNadal was one of the most successful teenagers in ATP Tour history, reaching No. 2 in the world and winning 16 titles before his 20th birthday, including his first French Open and six Masters events. Nadal became No. 1 for the first time in 2008 after his first major victory off clay against his rival, the longtime top-ranked Roger Federer, in a historic Wimbledon final. He also won an Olympic gold medal that year in singles in Beijing. After defeating Novak Djokovic at the 2010 US Open final, then 24-year-old Nadal became the youngest man in the Open Era to achieve the Career Grand Slam, and the first man to win three majors on three different surfaces (hard, grass and clay) in the same year (Surface Slam). With his Olympic gold medal, he is one of only two men to complete the Career Golden Slam in singles. Nadal is the only male player in history to complete the Career Grand Slam and win an Olympic gold medal in both singles and doubles.Since 2010, Nadal has continued to dominate at the French Open, winning at least four consecutive titles twice, while also winning three more US Open titles and another Australian Open title. He surpassed Djokovic and Federer's record for the most major men's singles titles at the 2022 Australian Open, and became one of four men in history to complete the double Career Grand Slam in singles. He also became the first and only man to win multiple majors in three separate decades. From 2005 to 2017, Nadal was coached by his uncle Toni Nadal.\\nNadal is the only left-handed member of the Big Three in men's singles. One of his main strengths is his forehand, which he routinely hits with extremely heavy topspin at difficult angles. He is one of the best at breaking serve, regularly appearing among the tour leaders in percentage of return games, return points, and break points won. Nadal has won the Stefan Edberg Sportsmanship Award five times, and was the Laureus World Sportsman of the Year in 2011 and 2021. He is also a recipient of the Grand Cross of the Order of Dos De Mayo, the Grand Cross of Naval Merit, the Princess of Asturias Award, and the Medal of the City of Paris. Representing Spain, he has won two Olympic gold medals, and led the nation to five Davis Cup titles. Nadal has also opened a tennis academy in Mallorca, and is an active philanthropist.\\n\\n\", \"Andrew Stephen Roddick (born 30 August 1982) is an American former world No. 1 tennis player. He is a major champion, having won the 2003 US Open. Roddick reached four other major finals (Wimbledon in 2004, 2005, and 2009, and the US Open in 2006), losing to rival Roger Federer each time. Roddick was ranked in the year-end top 10 for nine consecutive years (2002–2010) and won five Masters titles in that period. He was also a crucial player in the U.S. Davis Cup team's successful run to the title in 2007. As of June 2022, he is the most recent North American man to win a singles major (2003 US Open), the most recent to hold the world No. 1 ranking, and the most recent to claim the year-end world No. 1 ranking (which he achieved in 2003). Roddick retired from professional tennis following the 2012 US Open to focus on his work at the Andy Roddick Foundation. In retirement, Roddick played for the Austin Aces in World Team Tennis in 2015. He was also the 2015 and 2017 champion of the QQQ Champions Series. In 2017, Roddick was inducted into the International Tennis Hall of Fame. He is married to Brooklyn Decker, a swimwear model and actress.\", 'Michael Jeffrey Jordan (born February 17, 1963), also known by his initials MJ, is an American businessman and former professional basketball player. He played fifteen seasons in the National Basketball Association (NBA), winning six NBA championships with the Chicago Bulls. Jordan is the principal owner and chairman of the Charlotte Hornets of the NBA and of 23XI Racing in the NASCAR Cup Series. His biography on the official NBA website states: \"By acclamation, Michael Jordan is the greatest basketball player of all time.\" He was integral in popularizing the NBA around the world in the 1980s and 1990s, becoming a global cultural icon in the process.Jordan played college basketball for three seasons under coach Dean Smith with the North Carolina Tar Heels. As a freshman, he was a member of the Tar Heels\\' national championship team in 1982. Jordan joined the Bulls in 1984 as the third overall draft pick, and quickly emerged as a league star, entertaining crowds with his prolific scoring while gaining a reputation as one of the game\\'s best defensive players. His leaping ability, demonstrated by performing slam dunks from the free-throw line in Slam Dunk Contests, earned him the nicknames \"Air Jordan\" and \"His Airness\". Jordan won his first NBA title with the Bulls in 1991, and followed that achievement with titles in 1992 and 1993, securing a three-peat. Jordan abruptly retired from basketball before the 1993–94 NBA season to play Minor League Baseball but returned to the Bulls in March 1995 and led them to three more championships in 1996, 1997, and 1998, as well as a then-record 72 regular season wins in the 1995–96 NBA season. He retired for the second time in January 1999 but returned for two more NBA seasons from 2001 to 2003 as a member of the Washington Wizards.Jordan\\'s individual accolades and accomplishments include six NBA Finals Most Valuable Player (MVP) awards, ten NBA scoring titles (both all-time records), five NBA MVP awards, ten All-NBA First Team designations, nine All-Defensive First Team honors, fourteen NBA All-Star Game selections, three NBA All-Star Game MVP awards, three NBA steals titles, and the 1988 NBA Defensive Player of the Year Award. He holds the NBA records for career regular season scoring average (30.12 points per game) and career playoff scoring average (33.45 points per game). In 1999, he was named the 20th century\\'s greatest North American athlete by ESPN, and was second to Babe Ruth on the Associated Press\\' list of athletes of the century. Jordan was twice inducted into the Naismith Memorial Basketball Hall of Fame, once in 2009 for his individual career, and again in 2010 as part of the 1992 United States men\\'s Olympic basketball team (\"The Dream Team\"). He became a member of the United States Olympic Hall of Fame in 2009, a member of the North Carolina Sports Hall of Fame in 2010, and an individual member of the FIBA Hall of Fame in 2015 and a \"Dream Team\" member in 2017.One of the most effectively marketed athletes of his generation, Jordan is known for his product endorsements. He fueled the success of Nike\\'s Air Jordan sneakers, which were introduced in 1984 and remain popular today. Jordan also starred as himself in the 1996 live-action animation hybrid film Space Jam and is the central focus of the Emmy Award-winning documentary miniseries The Last Dance (2020). He became part-owner and head of basketball operations for the Charlotte Bobcats (now named the Hornets) in 2006, and bought a controlling interest in 2010. In 2016, Jordan became the first billionaire player in NBA history. As of 2022, his net worth is estimated at $2.1 billion.', \"Kareem Abdul-Jabbar (born Ferdinand Lewis Alcindor Jr.; April 16, 1947) is an American former professional basketball player who played 20 seasons in the National Basketball Association (NBA) for the Milwaukee Bucks and the Los Angeles Lakers. During his career as a center, Abdul-Jabbar was a record six-time NBA Most Valuable Player (MVP), a record 19-time NBA All-Star, a 15-time All-NBA Team member, and an 11-time NBA All-Defensive Team member. He was a member of six NBA championship teams as a player and two more as an assistant coach, and was twice voted NBA Finals MVP. He was named to three NBA anniversary teams (35th, 50th, and 75th). Widely regarded as one of the greatest players of all time, often named a top 3 player in NBA history, he was called the greatest basketball player of all time by Pat Riley, Isiah Thomas, and Julius Erving.With him on the team, parochial high school Power Memorial, in New York City, won 71 consecutive basketball games. He was recruited by Jerry Norman, the assistant coach at the University of California, Los Angeles (UCLA), where he played for coach John Wooden on three consecutive national championship teams. He was a record three-time MVP of the NCAA Tournament. Drafted with the first overall pick by the one-season-old Bucks franchise in the 1969 NBA draft, Alcindor spent six seasons in Milwaukee. After leading the Bucks to its first NBA championship at age 24 in 1971, he took the Muslim name Kareem Abdul-Jabbar. Using his trademark skyhook shot, he established himself as one of the league's top scorers. In 1975, he was traded to the Lakers, with whom he played the final 14 seasons of his career in which they won five additional NBA championships. Abdul-Jabbar's contributions were a key component in the Showtime era of Lakers basketball. Over his 20-year NBA career, his teams succeeded in making the playoffs 18 times and got past the first round 14 times; his teams reached the NBA Finals on ten occasions.At the time of his retirement at age 42 in 1989, Abdul-Jabbar was the NBA's all-time leader in points (38,387), games played (1,560), minutes (57,446), field goals made (15,837), field goal attempts (28,307), blocked shots (3,189), defensive rebounds (9,394), career wins (1,074), and personal fouls (4,657). He remains the all-time leader in points scored, field goals made, and career wins. He is ranked third all-time in both rebounds and blocked shots. ESPN named him the greatest center of all time in 2007, the greatest player in college basketball history in 2008, and the second best player in NBA history (behind Michael Jordan) in 2016. Abdul-Jabbar has also been an actor, a basketball coach, a best-selling author, and a martial artist, having trained in Jeet Kune Do under Bruce Lee and appeared in his film Game of Death (1972). In 2012, Abdul-Jabbar was selected by Secretary of State Hillary Clinton to be a U.S. global cultural ambassador. In 2016, President Barack Obama awarded him the Presidential Medal of Freedom.\", 'Larry Joe Bird (born December 7, 1956) is an American former professional basketball player, coach and executive in the National Basketball Association (NBA). Nicknamed \"the Hick from French Lick\" and \"Larry Legend\", Bird is widely regarded as one of the greatest basketball players of all time. Growing up in French Lick, Indiana, he was a local basketball star. Highly recruited, he initially signed to play college basketball for coach Bobby Knight of the Indiana Hoosiers, but dropped out after one month and returned to French Lick to attend a local community college. The next year he attended the smaller Indiana State University, playing ultimately for three years for the Sycamores. Drafted by the Boston Celtics with the sixth overall pick in the 1978 NBA draft after his second year at Indiana State, Bird elected to stay in college and play one more season. He then led his team to an undefeated regular season in 1978–1979. The season finished with a national championship game matchup against Michigan State, a team that featured Magic Johnson, beginning a career-long rivalry that the two shared for more than a decade.\\nBird entered the NBA for the 1979–1980 season, where he made an immediate impact, starting at power forward and leading the Celtics to a 32-win improvement over the previous season before being eliminated from the playoffs in the Conference Finals. He played for the Celtics during his entire professional career (13 seasons), leading them to five NBA finals appearances and three NBA championships. He played most of his career with forward Kevin McHale and center Robert Parish, considered by some to be the greatest front court in NBA history. Bird was a 12-time NBA All-Star, won two NBA Finals MVP awards and received the NBA Most Valuable Player Award three consecutive times (1984–1986), making him the only forward in league history to do so. Bird was also a member of the gold medal-winning 1992 United States men\\'s Olympic basketball team known as \"The Dream Team\". He was voted to the NBA\\'s 50th Anniversary All-Time Team in 1996, was inducted into the Naismith Memorial Basketball Hall of Fame in 1998, and was inducted into the Hall of Fame again in 2010 as a member of \"The Dream Team\". In October 2021, as part of the NBA\\'s 75th Anniversary, Bird was honored as one of the 75 greatest players of all time, by being named to the NBA\\'s 75th Anniversary Team.A versatile player at both forward positions, he could play both inside and outside, being one of the first players in the league to take advantage of the newly adopted three-point line. Bird was rated the greatest NBA small forward of all time by Fox Sports in 2016. After retiring as a player, Bird served as head coach of the Indiana Pacers from 1997 to 2000. He was named NBA Coach of the Year for the 1997–1998 season and later led the Pacers to a berth in the 2000 NBA Finals. In 2003, Bird was named president of basketball operations for the Pacers, holding the position until retiring in 2012. He was named NBA Executive of the Year for the 2012 season. Bird returned to the Pacers as president of basketball operations in 2013 and remained in that role until 2017.Bird is the only person in NBA history to be named Rookie of the Year, Most Valuable Player, Finals MVP, All-Star MVP, Coach of the Year, and Executive of the Year.', \"Michael Fred Phelps II (born June 30, 1985) is an American former competitive swimmer. He is the most successful and most decorated Olympian of all time with a total of 28 medals. Phelps also holds the all-time records for Olympic gold medals (23), Olympic gold medals in individual events (13), and Olympic medals in individual events (16). When Phelps won eight gold medals at the 2008 Beijing Games, he broke fellow American swimmer Mark Spitz's 1972 record of seven first-place finishes at any single Olympic Games. At the 2004 Summer Olympics in Athens, Phelps already tied the record of eight medals of any color at a single Games by winning six gold and two bronze medals. At the 2012 Summer Olympics in London, Phelps won four gold and two silver medals, and at the 2016 Summer Olympics in Rio de Janeiro, he won five gold medals and one silver. This made him the most successful athlete of the Games for the fourth Olympics in a row.Phelps is the long course world record holder in the men's 400-meter individual medley as well as the former long course world record holder in the 200-meter freestyle, 100-meter butterfly, 200-meter butterfly, and 200-meter individual medley. He has won 82 medals in major international long course competitions, of which 65 were gold, 14 silver, and three bronze, spanning the Olympics, the World Championships, and the Pan Pacific Championships. Phelps's international titles and record-breaking performances have earned him the World Swimmer of the Year Award eight times and American Swimmer of the Year Award eleven times, as well as the FINA Swimmer of the Year Award in 2012 and 2016. Phelps earned Sports Illustrated magazine's Sportsman of the Year award due to his unprecedented Olympic success in the 2008 Games.\\nAfter the 2008 Summer Olympics, Phelps started the Michael Phelps Foundation, which focuses on growing the sport of swimming and promoting healthier lifestyles. Phelps retired following the 2012 Olympics, but he made a comeback in April 2014. At the 2016 Summer Olympics in Rio de Janeiro, his fifth Olympics, he was selected by his team to be the flag bearer of the United States at the 2016 Summer Olympics Parade of Nations. He announced his second retirement on August 12, 2016, having won more medals than 161 countries. He is widely regarded as the greatest swimmer of all time and is often considered to be one of the greatest athletes of all time.\", \"Kathleen Genevieve Ledecky (born March 17, 1997) is an American competitive swimmer. Having won 6 Olympic individual gold medals and 13 world championship individual gold medals, the most in history for a female swimmer, she is considered one of the greatest Olympians and the greatest female swimmer of all time. Ledecky is the world record holder in the women's  800-, and 1500-meter freestyle (long course) as well as the former world record holder in the women's 400-meter freestyle (long course). She also holds the fastest-ever times in the women's 500-, 1000-, and 1650-yard freestyle events.\\nIn her international debut at the 2012 London Olympic Games as a 15-year-old, Ledecky unexpectedly won the gold medal in the women's 800-metre freestyle. Four years later, she left Rio de Janeiro as the most decorated female athlete of the 2016 Olympic Games, with four gold medals, one silver medal, and two world records. In total, she has won 40 medals (32 golds, 7 silvers, and 1 bronze) in major international competitions, spanning the Summer Olympics, World Championships, and Pan Pacific Championships. During her career, she has broken fourteen world records.\\nLedecky's success has earned her Swimming World's Female World Swimmer of the Year a record-breaking five times. Ledecky was also named Associated Press Female Athlete of the Year in 2017, international female Champion of Champions by L'Équipe in 2014 and 2017, United States Olympic Committee Female Athlete of the Year in 2013, 2016 and 2017, and Sportswoman of the Year by the Women's Sports Foundation in 2017. Ledecky's 11 individual gold medals at the World Aquatics Championships and 17 combined individual titles at the Olympics and World Aquatics Championships are records in women's swimming\\u200c.\", 'Ryan Steven Lochte ( LOK-tee; born August 3, 1984) is an American professional swimmer and 12-time Olympic medalist. Along with Natalie Coughlin, Dara Torres, and Jenny Thompson, he is the second-most decorated swimmer in Olympic history measured by total number of medals, behind only Michael Phelps. Lochte\\'s seven individual Olympic medals rank second in history in men\\'s swimming (again to Michael Phelps), tied for second among all Olympic swimmers. He currently holds the world records in the 200-meter individual medley (long and short course). As part of the American teams, he also holds the world record in the 4×200-meter freestyle (long course) and 4×100-meter freestyle (mixed) relay.\\nLochte\\'s success has earned him SwimSwam\\'s Swammy Award for U.S. Male Swimmer of the Year in 2013, the World Swimmer of the Year Award, and the American Swimmer of the Year Award twice. He has also been named the FINA Swimmer of the Year three times. He has won a total of 90 medals in major international competition (54 gold, 22 silver, and 14 bronze) spanning the Olympics, the World Championships, Pan American Games, and Pan Pacific Championships, including six Olympic gold medals and 39 world championship titles.\\nLochte specializes in the backstroke and individual medley, but is also a freestyle and butterfly swimmer. He is noted for the speed and distance he attains while kicking underwater. Lochte is also known for his dominance in the short course format (25-yard and 25-meter-long pools). Lochte swam the 100-meter individual medley in 50.71 seconds on December 15, 2012, at the FINA World Championships in Istanbul, Turkey. At this same event, he is also credited with swimming the fastest 200-meter individual medley, finishing in 1 minute 49.63 seconds.In 2016, Lochte generated international controversy when he claimed that he and three other American swimmers had been pulled over and robbed by armed men with police badges while in Rio de Janeiro, Brazil, at the 2016 Summer Olympics. While initial news stories reported that Lochte and three other US swimmers had been robbed at gunpoint after a night out in Rio, later details emerged that the \"armed robbers posing as police\" were actually security guards at a gas station where the swimmers had urinated outside the bathroom and Lochte allegedly vandalized a framed poster, and ended with the swimmers providing money to the guards. Some of the swimmers were detained in Brazil as witnesses. Ultimately, the athletes each released statements, and one swimmer paid a fine of approximately $10,800 to a Brazilian charity in order to get his passport back. Lochte apologized for not being more candid about the gas station dispute, and subsequently lost four major sponsorships. On September 8, both the U.S. Olympic Committee and USA Swimming suspended Lochte for 10 months and Bentz, Conger, and Feigen for four months. Additionally, Lochte was required to complete 20 hours of community service, and Bentz was required to complete 10 hours. All were made ineligible for financial support during their suspensions, removed from the U.S. Olympic delegation to the White House, barred from U.S. Olympic training centers, and blocked from attending USA Swimming\\'s year-end Golden Goggles celebration. Lochte was charged in Brazil with falsely reporting a crime.  The scandal gained significant media attention both during the games and after their conclusion. In July 2017, the court in Brazil dismissed the charges against Lochte, saying his actions \"did not rise to the level of filing a false crime report.\"On July 23, 2018, the U.S. Anti-Doping Agency imposed a 14-month suspension from competition on Lochte because he had received a \"prohibited intravenous infusion.\" Lochte immediately accepted the sanction. On May 24, 2018, the same day he had received the infusion, Lochte had posted a picture - since deleted - on Instagram \"showing him receiving an intravenous injection of what he says were \\'vitamins\\',\" even though the USADA bans \"intravenous infusions of permitted substances at volumes greater than 100 millilitres [3.5 imp fl oz; 3.4 US fl oz] in a 12-hour period without a special \\'Therapeutic Use Exemption\\',\" Vox reported.', 'The Beatles were an English rock band, formed in Liverpool in 1960, that comprised John Lennon, Paul McCartney, George Harrison and Ringo Starr. They are regarded as the most influential band of all time and were integral to the development of 1960s counterculture and popular music\\'s recognition as an art form. Rooted in skiffle, beat and 1950s rock \\'n\\' roll, their sound incorporated elements of classical music and traditional pop in innovative ways; the band later explored music styles ranging from ballads and Indian music to psychedelia and hard rock. As pioneers in recording, songwriting and artistic presentation, the Beatles revolutionised many aspects of the music industry and were often publicised as leaders of the era\\'s youth and sociocultural movements.Led by primary songwriters Lennon and McCartney, the Beatles evolved from Lennon\\'s previous group, the Quarrymen, and built their reputation playing clubs in Liverpool and Hamburg over three years from 1960, initially with Stuart Sutcliffe playing bass. The core trio of Lennon, McCartney and Harrison, together since 1958, went through a succession of drummers, including Pete Best, before asking Starr to join them in 1962. Manager Brian Epstein moulded them into a professional act, and producer George Martin guided and developed their recordings, greatly expanding their domestic success after signing to EMI Records and achieving their first hit, \"Love Me Do\", in late 1962. As their popularity grew into the intense fan frenzy dubbed \"Beatlemania\", the band acquired the nickname \"the Fab Four\", with Epstein, Martin and other members of the band\\'s entourage sometimes given the informal title of \"fifth Beatle\".\\nBy early 1964, the Beatles were international stars and had achieved unprecedented levels of critical and commercial success. They became a leading force in Britain\\'s cultural resurgence, ushering in the British Invasion of the United States pop market, and soon made their film debut with A Hard Day\\'s Night (1964). A growing desire to refine their studio efforts, coupled with the untenable nature of their concert tours, led to the band\\'s retirement from live performances in 1966. At this time, they produced records of greater sophistication, including the albums Rubber Soul (1965), Revolver (1966) and Sgt. Pepper\\'s Lonely Hearts Club Band (1967), and enjoyed further commercial success with The Beatles (also known as \"the White Album\", 1968) and Abbey Road (1969). Heralding the album era, their success elevated the album to the dominant form of record consumption over singles; they also inspired a greater public interest in psychedelic drugs and Eastern spirituality, and furthered advancements in electronic music, album art and music videos. In 1968, they founded Apple Corps, a multi-armed multimedia corporation that continues to oversee projects related to the band\\'s legacy. After the group\\'s break-up in 1970, all principal members enjoyed success as solo artists and some partial reunions have occurred. Lennon was murdered in 1980 and Harrison died of lung cancer in 2001. McCartney and Starr remain musically active.\\nThe Beatles are the best-selling music act of all time, with estimated sales of 600 million units worldwide. They hold the record for most number-one albums on the UK Albums Chart (15), most number-one hits on the Billboard Hot 100 chart (20), and most singles sold in the UK (21.9 million). The band received many accolades, including seven Grammy Awards, four Brit Awards, an Academy Award (for Best Original Song Score for the 1970 documentary film Let It Be) and fifteen Ivor Novello Awards. They were inducted into the Rock and Roll Hall of Fame in 1988, and each principal member was inducted individually between 1994 and 2015. In 2004 and 2011, the group topped Rolling Stone\\'s lists of the greatest artists in history. Time magazine named them among the 20th century\\'s 100 most important people.', 'The Rolling Stones are an English rock band formed in London in 1962. Active for six decades, they are one of the most popular and enduring bands of the rock era. In the early 1960s, the Rolling Stones pioneered the gritty, heavier-driven sound that came to define hard rock. Their first stable line-up consisted of vocalist Mick Jagger, multi-instrumentalist Brian Jones, guitarist Keith Richards, bassist Bill Wyman, and drummer Charlie Watts. During their formative years, Jones was the primary leader: he assembled the band, named it, and drove their sound and image. After Andrew Loog Oldham became the group\\'s manager in 1963, he encouraged them to write their own songs. Jagger and Richards became the primary creative force behind the band, alienating Jones, who had developed a drug addiction that interfered with his ability to contribute meaningfully.\\nRooted in blues and early rock and roll, the Rolling Stones started out playing covers and were at the forefront of the British Invasion in 1964, also being identified with the youthful and rebellious counterculture of the 1960s. They then found greater success with their own material as \"(I Can\\'t Get No) Satisfaction\" (1965), \"Get Off of My Cloud\" (1965) and \"Paint It Black\" (1966) became international No. 1 hits. Aftermath (1966) – their first entirely original album – is considered the most important of their formative records. In 1967, they had the double-sided hit \"Ruby Tuesday\"/\"Let\\'s Spend the Night Together\" and experimented with psychedelic rock on Their Satanic Majesties Request. They returned to their roots with such hits as \"Jumpin\\' Jack Flash\" (1968) and \"Honky Tonk Women\" (1969), and albums such as Beggars Banquet (1968), featuring \"Sympathy for the Devil\", and Let It Bleed (1969), featuring \"You Can\\'t Always Get What You Want\" and \"Gimme Shelter\". Let It Bleed was the first of five consecutive No. 1 albums in the UK.\\nJones left the band shortly before his death in 1969, having been replaced by guitarist Mick Taylor. That year they were first introduced on stage as \\'The Greatest Rock and Roll Band in the World\\'. Sticky Fingers (1971), which yielded \"Brown Sugar\" and included the first usage of their tongue and lips logo, was their first of eight consecutive No. 1 studio albums in the US. Exile on Main St. (1972), featuring \"Tumbling Dice\" and Goats Head Soup (1973), yielding the hit ballad \"Angie\", were also best sellers. Taylor was replaced by Ronnie Wood in 1974. The band continued to release successful albums, including their two largest sellers: Some Girls (1978), featuring \"Miss You\"; and Tattoo You (1981), featuring \"Start Me Up\". Steel Wheels (1989) was widely considered a comeback album and was followed by Voodoo Lounge (1994), a worldwide number one album. Both releases were promoted by large stadium and arena tours, as the Stones continued to be a huge concert attraction; by 2007 they had four of the top five highest-grossing concert tours of all time. From Wyman\\'s departure in 1993 to Watts\\' death in 2021, the band continued as a four-piece core, with Darryl Jones playing bass on tour and on most studio recordings. Their 2016 album, Blue & Lonesome, became their twelfth UK number-one album.\\nThe Rolling Stones\\' estimated record sales of 200 million make them one of the best-selling music artists of all time. The band has won three Grammy Awards and a Grammy Lifetime Achievement Award. They were inducted into the Rock and Roll Hall of Fame in 1989 and the UK Music Hall of Fame in 2004. In 2019, Billboard magazine ranked the Rolling Stones second on their list of the \"Greatest Artists of All Time\", based on US chart success. They are ranked fourth on Rolling Stone\\'s list of the Greatest Artists of All Time.', 'The Who are an English rock band formed in London in 1964. Their classic lineup consisted of lead singer Roger Daltrey, guitarist and singer Pete Townshend, bass guitarist and singer John Entwistle, and drummer Keith Moon. They are considered one of the most influential rock bands of the 20th century, and have sold over 100 million records worldwide. Their contributions to rock music include the development of the Marshall Stack, large PA systems, the use of the synthesizer, Entwistle and Moon\\'s influential playing styles, Townshend\\'s feedback and power chord guitar technique, and the development of the rock opera. They are cited as an influence by many hard rock, punk rock and mod bands, and their songs are still regularly played. The Who were inducted into the Rock and Roll Hall of Fame in 1990. \\nThe Who developed from an earlier group, the Detours, and established themselves as part of the pop art and mod movements, featuring auto-destructive art by destroying guitars and drums on stage. Their first single as the Who, \"I Can\\'t Explain\" (1965), reached the UK top ten, and was followed by a string of hit singles including \"My Generation\" (1965), \"Substitute\" (1966) and \"Happy Jack\" (1966). In 1967, they performed at the Monterey Pop Festival and released \"I Can See for Miles\", their only US top ten single. The group\\'s 1969 concept album Tommy included the single \"Pinball Wizard\" and was a critical and commercial success.\\nFurther festival appearances at Woodstock and the Isle of Wight, along with the concert album Live at Leeds (1970), established their reputation as a respected rock act. The success put pressure on lead songwriter Townshend, and the follow-up to Tommy, Lifehouse, was abandoned. Songs from the project made up Who\\'s Next (1971), including the hits \"Won\\'t Get Fooled Again\", \"Baba O\\'Riley\", and \"Behind Blue Eyes\". The group released another concept album, Quadrophenia (1973), as a celebration of their mod roots, and oversaw the film adaptation of Tommy (1975). They continued to tour to large audiences before semi-retiring from live performances at the end of 1976. The release of Who Are You (1978) was overshadowed by Moon\\'s death shortly after.\\nKenney Jones replaced Moon and the group resumed touring, and released a film adaptation of Quadrophenia and the retrospective documentary The Kids Are Alright. After Townshend became weary of the group, they split in 1983. The Who occasionally re-formed for live appearances such as Live Aid in 1985, a 25th anniversary tour in 1989 and a tour of Quadrophenia in 1996–1997. A full reunion began in 1999, with drummer Zak Starkey. After Entwistle\\'s death in 2002, plans for a new album were delayed until 2006, with Endless Wire.  Since Entwistle\\'s death, the Who have continued to perform and tour, most commonly with Starkey on drums, Pino Palladino on bass, and Pete\\'s brother Simon Townshend on second guitar and backing vocals. In 2019, the group released the album Who and toured with a symphony orchestra.\\n\\n', 'Edward Kennedy \"Duke\" Ellington (April 29, 1899 – May 24, 1974) was an American composer, pianist, and leader of a jazz orchestra from 1923 through the rest of his life.Born in Washington, D.C., Ellington was based in New York City from the mid-1920s and gained a national profile through his orchestra\\'s appearances at the Cotton Club in Harlem. In the 1930s, his orchestra toured Europe several times.\\nSome of the jazz musicians who were members of Ellington\\'s orchestra, such as saxophonist Johnny Hodges, are considered among the best players in the idiom.\\nEllington melded them into the best-regarded orchestral unit in the history of jazz. Some members stayed with the orchestra for several decades. A master at writing miniatures for the three-minute 78 rpm recording format, Ellington wrote or collaborated on more than one thousand compositions; his extensive body of work is the largest recorded personal jazz legacy, and many of his pieces have become standards. He also recorded songs written by his bandsmen, such as Juan Tizol\\'s \"Caravan\", which brought a Spanish tinge to big band jazz. At the end of the 1930s, Ellington began a nearly thirty-year collaboration with composer-arranger-pianist Billy Strayhorn, whom he called his writing and arranging companion. With Strayhorn, he composed multiple extended compositions, or suites, as well as many short pieces. For a few years at the beginning of Strayhorn\\'s involvement, Ellington\\'s orchestra is considered to have been at its peak, with bassist Jimmy Blanton and tenor saxophonist Ben Webster briefly members. Following a low-profile period (Hodges temporarily left), an appearance by Ellington and his orchestra at the Newport Jazz Festival in July 1956 led to a major revival and regular world tours. Ellington recorded for most American record companies of his era, performed in and scored several films, and composed a handful of stage musicals.\\nAlthough a pivotal figure in the history of jazz, in the opinion of Gunther Schuller and Barry Kernfeld, \"the most significant composer of the genre\", Ellington himself embraced the phrase \"beyond category\", considering it a liberating principle, and referring to his music as part of the more general category of American Music. Ellington was known for his inventive use of the orchestra, or big band, as well as for his eloquence and charisma. He was awarded a posthumous Pulitzer Prize Special Award for music in 1999.', \"John William Coltrane (September 23, 1926 – July 17, 1967) was an American jazz saxophonist and composer. \\nWorking in the bebop and hard bop idioms early in his career, Coltrane helped pioneer the use of modes and was one of the players at the forefront of free jazz. He led at least fifty recording sessions  and appeared on many albums by other musicians, including trumpeter Miles Davis and pianist Thelonious Monk. Over the course of his career, Coltrane's music took on an increasingly spiritual dimension, as exemplified on his most acclaimed albums A Love Supreme (1965) and Ascension (1966). \\nHe remains one of the most influential saxophonists in music history and has received numerous posthumous awards, including a Pulitzer Prize in 2007, and was canonized by the African Orthodox Church.His second wife was pianist and harpist Alice Coltrane.  The couple had three children: John Jr. (1964–1982), a bassist; Ravi (born 1965), a saxophonist; and Oran (born 1967), a saxophonist, guitarist, drummer and singer.\\n\\n\", 'Ahmad Jamal (born Frederick Russell Jones, July 2, 1930) is an American jazz pianist, composer, bandleader and educator. For six decades, he has been one of the most successful small-group leaders in jazz.\\n\\n', 'Katie Jane Perry (born 30 December 1980) is an English-born Australian fashion designer. Her label began in the Paddington Markets, and continued with a shop in Sydney.', 'Maroon 5 is an American pop rock band from Los Angeles, California. It currently consists of lead vocalist Adam Levine, keyboardist and rhythm guitarist Jesse Carmichael, lead guitarist James Valentine, drummer Matt Flynn, keyboardist PJ Morton and multi-instrumentalist and bassist Sam Farrar. Original members Levine, Carmichael, bassist Mickey Madden, and drummer Ryan Dusick first came together as Kara\\'s Flowers in 1994, while they were still in high school.\\nAfter self-releasing their independent album We Like Digging?, the band signed to Reprise Records and released the album The Fourth World in 1997. The album garnered a tepid response, after which the record label dropped the band and the members focused on college. In 2001, the band re-emerged as Maroon 5, pursuing a different direction and adding guitarist Valentine. The band signed with Octone Records, an independent record label with a separate joint venture relationship with J Records and released their debut album Songs About Jane in June 2002. Aided by the hit singles \"Harder to Breathe\", \"This Love\" and \"She Will Be Loved\", the album peaked at number six on the Billboard 200 chart and went quadruple platinum in 2005. In the same year, the band won the Grammy Award for Best New Artist. In 2006, Dusick left the band after suffering from serious wrist and shoulder injuries and was replaced by Matt Flynn.\\nThe band\\'s second album It Won\\'t Be Soon Before Long was released in May 2007. It debuted at number one on the US Billboard 200 chart and the lead single \"Makes Me Wonder\", became the band\\'s first number-one single on the Billboard Hot 100. In 2010, the band released the third album Hands All Over, to favorable reviews, re-releasing a year later to include the single \"Moves like Jagger\", which topped the Billboard Hot 100. In 2012, Carmichael left the group and was replaced by musician PJ Morton, as the band released the fourth album Overexposed, with the song \"One More Night\", topping the Billboard Hot 100 chart for nine consecutive weeks.\\nIn 2014, Carmichael rejoined the band alongside Morton to record the fifth album V (roman numeral pronounced \"five\"), with the band signed to Interscope Records and Levine\\'s own label 222 Records. Following the release of V, it reached number one on the Billboard 200. In 2016, Maroon 5 recruited their long-time collaborator Sam Farrar, as the band continued for the sixth studio album Red Pill Blues, which was released in November 2017. With the addition of Morton and Farrar, the band\\'s lineup increased to seven members. The successful singles of both albums \"Sugar\" and \"Girls Like You\" peaked at numbers two and one on the Hot 100 chart respectively. The band\\'s seventh album, Jordi, was released in June 2021. Maroon 5 has sold more than 135 million records, making them one of the world\\'s best-selling music artists.\\n\\n', 'Taylor Alison Swift (born December 13, 1989) is an American singer-songwriter. Her discography spans multiple genres, and her narrative songwriting—often inspired by her personal life—has received critical praise and widespread media coverage. Born in West Reading, Pennsylvania, Swift moved to Nashville, Tennessee, at the age of 14 to pursue a career in country music. She signed a songwriting contract with Sony/ATV Music Publishing in 2004 and a recording deal with Big Machine Records in 2005, and released her eponymous debut studio album in 2006.\\nSwift explored country pop on the albums Fearless (2008) and Speak Now (2010); the success of the singles \"Love Story\" and \"You Belong with Me\" on both country and pop radio established her as a leading crossover artist. She experimented with rock and electronic genres on her fourth studio album, Red (2012), supported by the singles \"We Are Never Ever Getting Back Together\" and \"I Knew You Were Trouble\". Swift eschewed country on her synth-pop album 1989 (2014) and its chart-topping tracks \"Shake It Off\", \"Blank Space\", and \"Bad Blood\". The media scrutiny on Swift\\'s life inspired Reputation (2017), which drew from urban sounds. Led by \"Look What You Made Me Do\", the album made Swift the only act in MRC Data history to have four albums each sell over a million copies in a week.\\nParting ways with Big Machine, Swift signed with Republic Records in 2018 and released her seventh studio album, Lover (2019). Inspired by escapism during the COVID-19 pandemic, Swift ventured into indie folk and alternative rock styles on her 2020 studio albums, Folklore and Evermore, receiving plaudits for their nuanced storytelling. Following a dispute over the masters of her back catalog, she released the 2021 re-recordings Fearless (Taylor\\'s Version) and Red (Taylor\\'s Version) to universal acclaim. The number-one songs \"Cardigan\", \"Willow\" and \"All Too Well (10 Minute Version)\" made Swift the only act to simultaneously debut atop the US Billboard Hot 100 and Billboard 200 charts three times. Besides music, she has played supporting roles in films such as Valentine\\'s Day (2010) and Cats (2019), released the autobiographical documentary Miss Americana (2020), and directed the musical films Folklore: The Long Pond Studio Sessions (2020) and All Too Well: The Short Film (2021).\\nWith over 200 million records sold worldwide, Swift is one of the best-selling musicians of all time. Eight of her songs have topped the Hot 100, and her concert tours are some of the highest-grossing in history. She has received 11 Grammy Awards (including three Album of the Year wins), an Emmy Award, 34 American Music Awards (the most for an artist), 29 Billboard Music Awards (the most for a woman) and 58 Guinness World Records, among other accolades. She has featured on Rolling Stone\\'s 100 Greatest Songwriters of All Time (2015), Billboard\\'s Greatest of All Time Artists (2019), the Time 100 and Forbes Celebrity 100 rankings. Having been honored with titles such as Woman of the Decade and Artist of the Decade, Swift is regarded as a pop icon due to her influential career, philanthropy, and advocacy for artists\\' rights and women\\'s empowerment.', 'Rigatoni (Italian: [riɡaˈtoːni]) are a form of tube-shaped pasta of varying lengths and diameters originating in Italy. They are larger than penne and ziti, and sometimes slightly curved. If so, they are not as curved as elbow macaroni. Rigatoni characteristically have ridges down their length, sometimes spiraling around the tube, and unlike penne, rigatoni\\'s ends are cut square (perpendicular) to the tube walls instead of diagonally.\\nThe word rigatoni comes from the Italian word rigato (rigatone being the augmentative and rigatoni the plural form), which means \"ridged\" or \"lined\", and is associated with the cuisine of southern and central Italy. Rigatoncini are a smaller version, close to the size of penne. Their name takes on the diminutive suffix -ino (pluralized -ini) denoting their relative size.\\nRigatoni is a particular favorite pasta shape in the south of Italy, especially in Sicily. Its eponymous ridges make better adhesive surfaces for sauces and grated cheese than smooth-sided pasta like ziti.', 'Spaghetti (Italian: [spaˈɡetti]) is a long, thin, solid, cylindrical pasta. It is a staple food of traditional Italian cuisine. Like other pasta, spaghetti is made of milled wheat and water and sometimes enriched with vitamins and minerals. Italian spaghetti is typically made from durum wheat semolina. Usually the pasta is white because refined flour is used, but whole wheat flour may be added. Spaghettoni is a thicker form of spaghetti, while capellini is a very thin spaghetti. \\nOriginally, spaghetti was notably long, but shorter lengths gained in popularity during the latter half of the 20th century and now it is most commonly available in 25–30 cm (10–12 in) lengths. A variety of pasta dishes are based on it and it is frequently served with tomato sauce or meat or vegetables.\\n\\n', 'Fusilli (Italian: [fuˈzilli]), commonly known as rotini in the United States, are a variety of pasta that are formed into corkscrew or helical shapes. The word fusilli presumably comes from fuso (\"spindle\"), as traditionally it is \"spun\" by pressing and rolling a small rod over the thin strips of pasta to wind them around it in a corkscrew shape.In addition to plain and whole wheat varieties, as with any pasta, other colours can be made by mixing other ingredients into the dough, which also affects the flavour, for example, beetroot or tomato for red, spinach for green, and cuttlefish ink for black.\\nThe term fusilli is also used to describe a short, extruded, twisted pasta known as rotini in the United States.', 'Peanuts is a syndicated daily and Sunday American comic strip written and illustrated by Charles M. Schulz. The strip\\'s original run extended from 1950 to 2000, continuing in reruns afterward. Peanuts is among the most popular and influential in the history of comic strips, with 17,897 strips published in all, making it \"arguably the longest story ever told by one human being\". At the time of Schulz\\'s death in 2000, Peanuts ran in over 2,600 newspapers, with a readership of around 355 million in 75 countries, and was translated into 21 languages. It helped to cement the four-panel gag strip as the standard in the United States, and together with its merchandise earned Schulz more than $1 billion.Peanuts focuses entirely on a social circle of young children, where adults exist but are never seen and rarely heard. The main character, Charlie Brown, is meek, nervous, and lacks self-confidence. He is unable to fly a kite, win a baseball game, or kick a football held by his irascible friend Lucy, who always pulls it away at the last instant. Peanuts is one of several literate strips with philosophical, psychological, and sociological overtones that flourished in the 1950s. Peanuts\\'s humor is psychologically complex and driven by the characters\\' interactions and relationships.\\nPeanuts achieved considerable success with its television specials, several of which, including A Charlie Brown Christmas and It\\'s the Great Pumpkin, Charlie Brown, won or were nominated for Emmy Awards. The Peanuts holiday specials remain popular and had been broadcast on network television for over 50 years before moving to the Apple TV+ streaming service in 2020. In addition, the specials occasionally rerun on PBS and PBS Kids since 2020. Peanuts also had successful adaptations in theatre, with the stage musical You\\'re a Good Man, Charlie Brown an oft-performed production. In 2013, TV Guide ranked the Peanuts television specials the fourth-greatest TV cartoon of all time. A computer-animated feature film based on the franchise was released in 2015.\\n\\n', 'The chickpea or chick pea (Cicer arietinum) is an annual legume of the family Fabaceae, subfamily Faboideae. Its different types are variously known as gram or Bengal gram, garbanzo or garbanzo bean, or Egyptian pea.  Chickpea seeds are high in protein. It is one of the earliest cultivated legumes, and 9500-year-old remains have been found in the Middle East.The chickpea is a key ingredient in Mediterranean and Middle Eastern cuisines, used in hummus, and, when ground into flour, falafel. It also is important in Indian cuisine, used in salads, soups and stews, and curry, in chana masala,  and in other meal products like channa. In 2019, India was responsible for 70% of global chickpea production.', 'The black turtle bean is a small, shiny variety of the common bean (Phaseolus vulgaris) especially popular in Latin American cuisine, though it can also be found in the Cajun and Creole cuisines of south Louisiana. Like all varieties of the common bean, it is native to the Americas, but has been introduced around the world. It is also used in Indian cuisine, Tamil cuisine, where it is known as karuppu kaaramani and in Maharashtrian cuisine, where it is known as Kala Ghevada.  The black turtle bean is often simply called the black bean (frijoles negros, zaragoza, judía negra, poroto negro, caraota negra, or habichuela negra in Spanish; and feijão preto in Portuguese), although this terminology can cause confusion with at least three other types of black beans.\\nThe black turtle bean is the only type of turtle bean. It is called turtle because of its hard outer \"shell\".\\n\\n', 'Rye bread is a type of bread made with various proportions of flour from rye grain. It can be light or dark in color, depending on the type of flour used and the addition of coloring agents, and is typically denser than bread made from wheat flour. Compared to white bread, it is higher in fiber, darker in color, and stronger in flavor.\\nRye bread was considered a staple through the Middle Ages. Many different types of rye grain have come from north-central, western, and eastern European countries such as Iceland, Germany, Austria, Denmark, Sweden, Norway, Finland, Estonia, Latvia, Lithuania, Poland, Belarus, Ukraine, Russia, the Netherlands, Belgium, France, and the Czech Republic and is also a specialty in the canton of Valais in Switzerland. Around 500 AD, the Germanic tribe of Saxons settled in Britain and introduced rye, which was well-suited to its temperate climates.\\n\\n', 'Sourdough is a bread made by the fermentation of dough using wild lactobacillaceae and yeast. Lactic acid from fermentation imparts a sour taste and improves keeping qualities.', \"A bagel (Yiddish: בײגל, romanized: beygl; Polish: bajgiel; also historically spelled beigel) is a bread product originating in the Jewish communities of Poland. It is traditionally shaped by hand into the form of a ring from yeasted wheat dough, roughly hand-sized, that is first boiled for a short time in water and then baked. The result is a dense, chewy, doughy interior with a browned and sometimes crisp exterior. Bagels are often topped with seeds baked on the outer crust, with the traditional ones being poppy and sesame seeds. Some may have salt sprinkled on their surface, and there are different dough types, such as whole-grain and rye.The earliest known mention of a boiled-then-baked ring-shaped bread can be found in a 13th-century Arabic cookbook, where they are referred to as ka'ak. Bagels have been widely associated with Ashkenazi Jews since the 17th century; they were first mentioned in 1610 in Jewish community ordinances in Kraków, Poland. Bagel-like bread known as obwarzanek was common earlier in Poland as seen in royal family accounts from 1394.Bagels are now a popular bread product in North America and Poland, especially in cities with a large Jewish population, many with alternative ways of making them. Bagels are also sold (fresh or frozen, often in many flavors) in  supermarkets.\\nThe basic roll-with-a-hole design is hundreds of years old and has other practical advantages besides providing more even cooking and baking of the dough: The hole could be used to thread string or dowels through groups of bagels, allowing easier handling and transportation and more appealing seller displays.\"]\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "from wikipedia.exceptions import WikipediaException\n",
    "\n",
    "'''\n",
    " Generate a list of wikipedia article to cluster \n",
    " You can maintain a static list of titles or generate them randomly using wikipedia library\n",
    " Some topics include:\n",
    " [\"Northeastern Unversity\", \"Natural language processing\", \"Machine learning\", \"Quantum machine learning\", \"Artificial intelligence\", \"Data science\", \"Master in Data Science\", \n",
    " \"Bank of America\", \"Visa Inc.\", \"European Central Bank\", \"Bank\", \"Financial technology\",\"International Monetary Fund\", \n",
    " \"Basketball\", \"Swimming\", \"Tennis\", \"Football\", \"College Football\", \"Association Football\"]\n",
    "\n",
    " You can add more topics from different categories so that we have a diverse dataset to work with. \n",
    " Ex- About 3+ categories(groups), 3+ topics in each category, 3+ articles in each topic\n",
    "'''\n",
    "#help(wikipedia)\n",
    "# selected topics\n",
    "topics = ['Tennis', 'Basketball', 'Swimming', 'Rock and Roll', 'Jazz', 'Pop', 'Pasta', 'Legumes', 'Bread']\n",
    "\n",
    "# list of articles to be downloaded\n",
    "articles = ['Roger Federer', 'Rafael Nadal', 'Andy Roddick', 'Michael Jordan', 'Kareem Abdul-Jabbar', 'Larry Bird', 'Michael Phelps', 'Katie Ledecky', 'Ryan Lochte', 'The Beatles', 'The Rolling Stones', 'The Who', 'Duke Ellington', 'John Coltrane', 'Ahmad Jamal', 'Katie Perry', 'Maroon 5', 'Taylor Swift', 'Rigatoni', 'Spaghetti', 'Rotini', 'Peanuts', 'Chickpeas', 'Black turtle bean', 'Rye bread', 'Sourdough', 'Bagel']\n",
    "# download and store articles (summaries) in this variable\n",
    "data = []\n",
    "for article in articles:\n",
    "    art = wikipedia.summary(article, auto_suggest = False)\n",
    "    data.append(art)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgpRv7wQ4Dpm"
   },
   "source": [
    "### Cleaning the Data (5 points)\n",
    "In this step you will decide whether to clean the data or not. If you choose to clean, you may utilize the clean function from assignment 1.\n",
    "\n",
    "**Question:** Why are you (not) choosing to clean the data? Think in terms of whether cleaning data will help in the clustering or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnZpDKcaHTGq"
   },
   "source": [
    "**Answer(1-3 sentences):** I choose not to clean this data. I don't necessarily want to force a lower case, yes there is the effect of separating words that begin sentences, but I don't want to lose the meaning that could result from a proper noun like 'Baker', potentially a signifying element, being mistaken for a 'baker'. The tfidf function means stopwords aren't really a concern except computationally. I also don't want to remove non-alphanumeric characters because they could have very significant meaning; an integration sign would heavily imply a mathematical nature to the article; also because foreign names should not be excluded and sometimes have less typical characters which should remain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lNj53Pxr963N"
   },
   "outputs": [],
   "source": [
    "# You can use Assignment 1's clean message function\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "def clean_message(message):\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvRZUpmq-DmT"
   },
   "source": [
    "### Vectorize the articles (5 points)\n",
    "\n",
    "In this step, we will vectorize the text data. You can use TfidfVectorizer() or countVectorizer() from sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gJk8YY89-OU4"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvec = TfidfVectorizer()\n",
    "X = tfidfvec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DAIGlqEuINWA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 2333)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKLvrKHRQaQq"
   },
   "source": [
    "### Sample Output:\n",
    "(36, 1552)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5ZrGrzD_G8d"
   },
   "source": [
    "### Plot Articles (10 points)\n",
    "Now we will try to verify the groups of articles using T-SNE from sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "SjcuZBOe-oZq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jommc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:795: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    " from sklearn.manifold import TSNE\n",
    "\n",
    "# call TSNE() to fit the data\n",
    "tsne_X = TSNE(n_components=2, perplexity = 5, learning_rate=50, n_iter = 10000).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCY_blxjO1bs"
   },
   "source": [
    "Plot and annotate the points with different markers for different expected groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "3ODUA1Vf-rRd",
    "outputId": "325b5db4-60d1-4907-a487-40893e256ee1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get a figure handle\n",
    "\n",
    "#sports\n",
    "sportsX = tsne_X[0:9,0]\n",
    "sportsY = tsne_X[0:9,1]\n",
    "#music\n",
    "musicX = tsne_X[9:18,0]\n",
    "musicY = tsne_X[9:18,1]\n",
    "#food\n",
    "foodX = tsne_X[18:27,0]\n",
    "foodY = tsne_X[18:27,1]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,8))\n",
    "plt.scatter(sportsX, sportsY, c = 'blue', label='Sports')\n",
    "plt.scatter(musicX, musicY, c = 'red', label = 'Music')\n",
    "plt.scatter(foodX, foodY, c = 'green', label = 'Food')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYcEi1EC_UGO"
   },
   "source": [
    "**Question:** Comment about the categorizion done by T-SNE. Do the articles of related topics cluster together? (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tde1Wu5HI6AA"
   },
   "source": [
    "**Answer(1-3 sentences):**  \n",
    "  It took some time to find the right parameterization. The trick in this case was a lower learning rate and a lower perplexity than are default. But, finally, tSNE was able to reliably cluster the three categories, though the clustering isn't very tight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2xrJddIpSsd"
   },
   "source": [
    "# Question 3 Building Neural Networks\n",
    "\n",
    "### We are gonna use Emotions Dataset for this task. We need to classify the given text into different kind of emotions like happy,sad,anger etc.., \n",
    "\n",
    "### We are providing train.txt and val.txt files along with this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJYmVbkvphgX"
   },
   "source": [
    "### Library Imports and Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BO-HU-7uorVX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jommc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jommc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\jommc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "#string.punctuation\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "ps = nltk.PorterStemmer()\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "  # From the last assignment\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"www.\\S+\", \"\", text)\n",
    "    text_links_removed = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text_cleaned = \" \".join([word for word in re.split('\\W+', text_links_removed)\n",
    "        if word not in stopword])\n",
    "    text = \" \".join([wn.lemmatize(word) for word in re.split('\\W+', text_cleaned)])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0D5wVjZw7s0"
   },
   "source": [
    "### Q) Importing the datasets and do the necessary cleaning and convert the text into the vectors which are mentioned in the below code blocks. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "MOMhmIlGprK9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 2)\n",
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Import the train.txt and val.txt file into pandas dataframe format \n",
    "\n",
    "# train \n",
    "train = pd.read_csv('train.txt', sep = ';', header = None)\n",
    "# validation\n",
    "val = pd.read_csv('val.txt', sep = ';', header = None)\n",
    "# and printout the train.shape and validation.shape \n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "# expected shape of train dataset is (16000,2) and validation dataset is (2000,2)\n",
    "#numpy, because I have an easier time with it than pandas\n",
    "train = train.to_numpy()\n",
    "x_train = train[:,0]\n",
    "y_train = train[:,1]\n",
    "val = val.to_numpy()\n",
    "x_val = val[:,0]\n",
    "y_val = val[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PS7K3p7AqAI8"
   },
   "outputs": [],
   "source": [
    "# clean the text in the train and validation dataframes using the clean_text function provided above\n",
    "for i in range(len(train)):\n",
    "    x_train[i] = clean_text(x_train[i])\n",
    "\n",
    "for i in range(len(val)):\n",
    "    x_val[i] = clean_text(x_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GxZC6RIjq3bu"
   },
   "outputs": [],
   "source": [
    "# initialise count vectorizer from sklearn module with default parameter\n",
    "countVec = CountVectorizer()\n",
    "# fit on train dataset and transform both train and validation dataset\n",
    "countVec.fit(x_train,y_train)\n",
    "countTrain = countVec.transform(x_train)\n",
    "countVal = countVec.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "85nuazEzq3YT"
   },
   "outputs": [],
   "source": [
    "# initialise tfidf vectorizer from sklearn module with default parameter\n",
    "tfidfVec = TfidfVectorizer()\n",
    "# fit on train dataset and transform both train and validation dataset\n",
    "tfidfVec.fit(x_train,x_train)\n",
    "tfidfTrain = tfidfVec.transform(x_train)\n",
    "tfidfVal = tfidfVec.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jgHWAuG-q3Vm"
   },
   "outputs": [],
   "source": [
    "# initialise label encoder from sklearn module\n",
    "le = preprocessing.LabelEncoder()\n",
    "# fit on train labels and transform both train and validation labels\n",
    "le.fit(y_train)\n",
    "leTrain = le.transform(y_train)\n",
    "leVal = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Wjdye0tvq3So"
   },
   "outputs": [],
   "source": [
    "# convert the labels into one hot encoding form | I CANNOT FIND ANYTHING THAT WILL EXPLAIN HOW THIS WORKS FOR ME\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "#ohe.fit(leTrain)\n",
    "#oheTrain = ohe.transform(y_train)\n",
    "#oheVal = ohe.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = []\n",
    "for i in range(len(train)):\n",
    "    if train[i,1] not in unique_classes:\n",
    "        unique_classes.append(train[i,1])\n",
    "\n",
    "num_classes = len(unique_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjsiH8YOw-Da"
   },
   "source": [
    "### Q) Build the neural networks using tensorflow keras by following the below instructions. Evaluate the model on different metrics and comment your observations. (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "AQg14bkTq3KB"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# complete this linear model in tensorflow\n",
    "def build_model(X):\n",
    "    model = tf.keras.Sequential()\n",
    "    # layer 1 : input layer\n",
    "    inp = tf.keras.Input((X.shape[1],))\n",
    "    model.add(inp)\n",
    "    # layer 2 : add the dense layer with 2048 units and relu activation\n",
    "    model.add(tf.keras.layers.Dense(2048, activation = 'relu'))\n",
    "    # layer 3 : add the dropout layer with dropout rate of 0.5\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    # layer 4 : add the dense layer with 1024 units with tanh activation and with l2 regularization\n",
    "    model.add(tf.keras.layers.Dense(1024, activation = 'tanh', activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "    # layer 5 : add the dropout layer with dropout rate of 0.5\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    # layer 6 : add the dense layer with 512 units with tanh activation and with l2 regularization\n",
    "    model.add(tf.keras.layers.Dense(512, activation = 'tanh', activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "    # layer 7 : add the dropout layer with dropout rate of 0.5\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    # layer 8 : add the dense layer with 256 units with tanh activation and with l2 regularization\n",
    "    model.add(tf.keras.layers.Dense(256, activation = 'tanh', activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "    # layer 9 : add the dropout layer with dropout rate of 0.5\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    # layer 10 : add the dense layer with 128 units with tanh activation and with l2 regularization\n",
    "    model.add(tf.keras.layers.Dense(128, activation = 'tanh', activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "    # layer 11 : add the dropout layer with dropout rate of 0.5\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    # layer 12 : output layer with units equal to number of classes and activation as softmax\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation = 'softmax'))\n",
    "    # use loss as categorical crossentropy, optimizer as rmsprop and evaluate model on auc,precision,recall,accuracy \n",
    "    model.compile(optimizer = tf.keras.optimizers.RMSprop(), loss = tf.keras.losses.CategoricalCrossentropy(), \n",
    "                 metrics = [tf.keras.metrics.AUC(), tf.keras.metrics.Accuracy(), tf.keras.metrics.Precision(), \n",
    "                           tf.keras.metrics.Recall()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Q71CC1pIsx0O"
   },
   "outputs": [],
   "source": [
    "# call the build_model function and initialize the model\n",
    "countTrain.shape\n",
    "model = build_model(countTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "KyAZNgsBsxwo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 0 ... 2 0 4]\n",
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]]\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 328s 164ms/step - loss: 0.8597 - auc: 0.9533 - accuracy: 0.0000e+00 - precision: 0.8389 - recall: 0.7121\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 324s 162ms/step - loss: 0.8821 - auc: 0.9505 - accuracy: 0.0000e+00 - precision: 0.8364 - recall: 0.7021\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 313s 156ms/step - loss: 0.8784 - auc: 0.9502 - accuracy: 0.0000e+00 - precision: 0.8382 - recall: 0.6990\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 313s 157ms/step - loss: 0.8850 - auc: 0.9498 - accuracy: 0.0000e+00 - precision: 0.8375 - recall: 0.6979\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 315s 157ms/step - loss: 0.8759 - auc: 0.9506 - accuracy: 0.0000e+00 - precision: 0.8394 - recall: 0.6966\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 314s 157ms/step - loss: 0.8986 - auc: 0.9476 - accuracy: 1.0417e-05 - precision: 0.8362 - recall: 0.6903\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 310s 155ms/step - loss: 0.8825 - auc: 0.9492 - accuracy: 1.0417e-05 - precision: 0.8399 - recall: 0.6924\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 314s 157ms/step - loss: 0.8877 - auc: 0.9484 - accuracy: 0.0000e+00 - precision: 0.8440 - recall: 0.6955\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 313s 157ms/step - loss: 0.8827 - auc: 0.9496 - accuracy: 0.0000e+00 - precision: 0.8468 - recall: 0.6979\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 313s 157ms/step - loss: 0.8986 - auc: 0.9474 - accuracy: 0.0000e+00 - precision: 0.8405 - recall: 0.6911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201a8a33fd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and validate the model on the count vectors of text which we have created initially for 10 epochs, \n",
    "# adjust batch size according to your computation power (suggestion use : 8)\n",
    "y = tf.keras.utils.to_categorical(leTrain, num_classes) #necessary because I did not understand sklearn's one hot encoding\n",
    "model.fit(countTrain, y, batch_size = 8, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions 2000 and 16000 are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m y_test \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(leTrain, num_classes)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcountVal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:298\u001b[0m, in \u001b[0;36mDimension.assert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m\"\"\"Raises an exception if `other` is not compatible with this Dimension.\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03m    is_compatible_with).\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_compatible_with(other):\n\u001b[1;32m--> 298\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimensions \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m are not compatible\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    299\u001b[0m                    (\u001b[38;5;28mself\u001b[39m, other))\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions 2000 and 16000 are not compatible"
     ]
    }
   ],
   "source": [
    "y_test = tf.keras.utils.to_categorical(leTrain, num_classes)\n",
    "model.evaluate(countVal, y_test, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nS02IwLCsxmG"
   },
   "outputs": [],
   "source": [
    "# plot train loss vs val loss, train auc vs val auc, train recall vs val recall, train precision vs val precision and train accuracy vs val accuracy and comment your observations\n",
    "\n",
    "#MY TRAINING ACCURACY READS AS 0, DESPITE USING THE FUNCTION AS DEFINED IN THE DOCUMENTATION https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6FHdCcp7wXyw"
   },
   "outputs": [],
   "source": [
    "# again call the build_model function and initialize the model\n",
    "model2 = build_model(tfidfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "k4gB80M6wXvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 635s 317ms/step - loss: 1.1982 - auc_3: 0.8928 - accuracy: 0.0000e+00 - precision_2: 0.7626 - recall_2: 0.4785\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 623s 311ms/step - loss: 0.7684 - auc_3: 0.9665 - accuracy: 0.0000e+00 - precision_2: 0.8551 - recall_2: 0.7579\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 627s 313ms/step - loss: 0.7126 - auc_3: 0.9712 - accuracy: 0.0000e+00 - precision_2: 0.8600 - recall_2: 0.7826\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 632s 316ms/step - loss: 0.7223 - auc_3: 0.9702 - accuracy: 1.0417e-05 - precision_2: 0.8551 - recall_2: 0.7796\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 634s 317ms/step - loss: 0.7289 - auc_3: 0.9699 - accuracy: 2.0833e-05 - precision_2: 0.8545 - recall_2: 0.7775\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 635s 317ms/step - loss: 0.7451 - auc_3: 0.9680 - accuracy: 1.0417e-05 - precision_2: 0.8556 - recall_2: 0.7782\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 638s 319ms/step - loss: 0.7451 - auc_3: 0.9685 - accuracy: 2.0833e-05 - precision_2: 0.8564 - recall_2: 0.7769\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 632s 316ms/step - loss: 0.7598 - auc_3: 0.9675 - accuracy: 3.1250e-05 - precision_2: 0.8522 - recall_2: 0.7729\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 631s 315ms/step - loss: 0.7545 - auc_3: 0.9683 - accuracy: 2.0833e-05 - precision_2: 0.8552 - recall_2: 0.7716\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 635s 318ms/step - loss: 0.7731 - auc_3: 0.9661 - accuracy: 4.1667e-05 - precision_2: 0.8521 - recall_2: 0.7673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ff80b7be50>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and validate the model on the tfidf vectors of text which we have created initially for 10 epochs, \n",
    "# adjust batch size according to your computation power (suggestion use : 8)\n",
    "model2.fit(tfidfTrain.todense(), y, batch_size = 8, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[1] = [0,10992] is out of order. Many sparse ops require sorted indices.\n    Use `tf.sparse.reorder` to create a correctly ordered copy.\n\n [Op:SerializeManySparse]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidfVal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[1] = [0,10992] is out of order. Many sparse ops require sorted indices.\n    Use `tf.sparse.reorder` to create a correctly ordered copy.\n\n [Op:SerializeManySparse]"
     ]
    }
   ],
   "source": [
    "model2.evaluate(tfidfVal, y_test, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsnEOHXRwXkv"
   },
   "outputs": [],
   "source": [
    "# plot train loss vs val loss, train auc vs val auc, train recall vs val recall, train precision vs val precision and train accuracy vs val accuracy and comment your observations\n",
    "\n",
    "#MY TRAINING ACCURACY READS AS 0, DESPITE USING THE FUNCTION AS DEFINED IN THE DOCUMENTATION https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4adDDQWeQyGb"
   },
   "source": [
    "## Question 4 Theory Question  \n",
    "\n",
    "What is the difference between Count Vectorizer, TFIDF, Word2Vec and Glove? (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXTRkF6KRB_D"
   },
   "source": [
    "**Answer:** \n",
    "Count Vectorizer just counts the number of appearances of a word in a document.\n",
    "TFIDF aims to highly rate the words that seem to have the most impact through scaling inverse document frequency by term frequency.\n",
    "Word2Vec creates a much denser vector than the above two. It uses embeddings where similar words or words commonly sharing context have similar embedding vectors. This can increase generalizability.\n",
    "GloVe is another kind of embedding model. Instead based on the co-occurance of words in the corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQQsqcto79zE"
   },
   "source": [
    "What is the significant difference between the Niave Bayes Implementation using Bag of Words and TF-IDF? (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtiPCTZM8Aua"
   },
   "source": [
    "**Answer:**\n",
    "The biggest difference is that the probabilities using the BoW approach will depend in magnitude on the absolute number of appearances of the word; whereas for the TF-IDF version, the biggest probabilities will belong to the words with the largest impact (as defined by TF-IDF). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OaXBo1Bw8C1K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS6120_NLP_Assignment_2_Notebook",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
